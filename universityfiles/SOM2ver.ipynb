{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqsTZOLcwziX"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np # NUMPY\n",
        "import pandas as pd # PANDAS\n",
        "import matplotlib.pyplot as plt # MATPLOTLIB\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "%run /content/SynthesisEmotions/Notebook/auxfunctions.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nAlOAcc_w8T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script to implement simple self organizing map using PyTorch, with methods\n",
        "similar to clustering method in sklearn.\n",
        "\n",
        "@author: Riley Smith\n",
        "Created: 1-27-21\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class SOM2():\n",
        "    \"\"\"\n",
        "    The 2-D, rectangular grid self-organizing map class using Numpy.\n",
        "    \"\"\"\n",
        "    def __init__(self, m=3, n=3, dim=3, lr=1, sigma=1, max_iter=3000,\n",
        "                    random_state=None):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        m : int, default=3\n",
        "            The shape along dimension 0 (vertical) of the SOM.\n",
        "        n : int, default=3\n",
        "            The shape along dimesnion 1 (horizontal) of the SOM.\n",
        "        dim : int, default=3\n",
        "            The dimensionality (number of features) of the input space.\n",
        "        lr : float, default=1\n",
        "            The initial step size for updating the SOM weights.\n",
        "        sigma : float, optional\n",
        "            Optional parameter for magnitude of change to each weight. Does not\n",
        "            update over training (as does learning rate). Higher values mean\n",
        "            more aggressive updates to weights.\n",
        "        max_iter : int, optional\n",
        "            Optional parameter to stop training if you reach this many\n",
        "            interation.\n",
        "        random_state : int, optional\n",
        "            Optional integer seed to the random number generator for weight\n",
        "            initialization. This will be used to create a new instance of Numpy's\n",
        "            default random number generator (it will not call np.random.seed()).\n",
        "            Specify an integer for deterministic results.\n",
        "        \"\"\"\n",
        "        # Initialize descriptive features of SOM\n",
        "        self.m = m\n",
        "        self.n = n\n",
        "        self.dim = dim\n",
        "        self.shape = (m, n)\n",
        "        self.initial_lr = lr\n",
        "        self.lr = lr\n",
        "        self.sigma = sigma\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "        # Initialize weights\n",
        "        self.random_state = random_state\n",
        "        rng = np.random.default_rng(random_state)\n",
        "        self.weights = rng.normal(size=(m * n, dim))\n",
        "        self._locations = self._get_locations(m, n)\n",
        "\n",
        "        # Set after fitting\n",
        "        self._inertia = None\n",
        "        self._n_iter_ = None\n",
        "        self._trained = False\n",
        "\n",
        "    def _get_locations(self, m, n):\n",
        "        \"\"\"\n",
        "        Return the indices of an m by n array.\n",
        "        \"\"\"\n",
        "        return np.argwhere(np.ones(shape=(m, n))).astype(np.int64)\n",
        "\n",
        "    def _find_bmu(self, x):\n",
        "        \"\"\"\n",
        "        Find the index of the best matching unit for the input vector x.\n",
        "        \"\"\"\n",
        "        # Stack x to have one row per weight\n",
        "        x_stack = np.stack([x]*(self.m*self.n), axis=0)\n",
        "        # Calculate distance between x and each weight\n",
        "        distance = np.linalg.norm(x_stack - self.weights, axis=1)\n",
        "        # Find index of best matching unit\n",
        "        return np.argmin(distance)\n",
        "\n",
        "    def step(self, x):\n",
        "        \"\"\"\n",
        "        Do one step of training on the given input vector.\n",
        "        \"\"\"\n",
        "        # Stack x to have one row per weight\n",
        "        x_stack = np.stack([x]*(self.m*self.n), axis=0)\n",
        "\n",
        "        # Get index of best matching unit\n",
        "        bmu_index = self._find_bmu(x)\n",
        "\n",
        "        # Find location of best matching unit\n",
        "        bmu_location = self._locations[bmu_index,:]\n",
        "\n",
        "        # Find square distance from each weight to the BMU\n",
        "        stacked_bmu = np.stack([bmu_location]*(self.m*self.n), axis=0)\n",
        "        bmu_distance = np.sum(np.power(self._locations.astype(np.float64) - stacked_bmu.astype(np.float64), 2), axis=1)\n",
        "\n",
        "        # Compute update neighborhood\n",
        "        neighborhood = np.exp((bmu_distance / (self.sigma ** 2)) * -1)\n",
        "        local_step = self.lr * neighborhood\n",
        "\n",
        "        # Stack local step to be proper shape for update\n",
        "        local_multiplier = np.stack([local_step]*(self.dim), axis=1)\n",
        "\n",
        "        # Multiply by difference between input and weights\n",
        "        delta = local_multiplier * (x_stack - self.weights)\n",
        "\n",
        "        # Update weights\n",
        "        self.weights += delta\n",
        "\n",
        "    def _compute_point_intertia(self, x):\n",
        "        \"\"\"\n",
        "        Compute the inertia of a single point. Inertia defined as squared distance\n",
        "        from point to closest cluster center (BMU)\n",
        "        \"\"\"\n",
        "        # Find BMU\n",
        "        bmu_index = self._find_bmu(x)\n",
        "        bmu = self.weights[bmu_index]\n",
        "        # Compute sum of squared distance (just euclidean distance) from x to bmu\n",
        "        return np.sum(np.square(x - bmu))\n",
        "\n",
        "    def fit(self, X, epochs=1, shuffle=True):\n",
        "        \"\"\"\n",
        "        Take data (a tensor of type float64) as input and fit the SOM to that\n",
        "        data for the specified number of epochs.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray\n",
        "            Training data. Must have shape (n, self.dim) where n is the number\n",
        "            of training samples.\n",
        "        epochs : int, default=1\n",
        "            The number of times to loop through the training data when fitting.\n",
        "        shuffle : bool, default True\n",
        "            Whether or not to randomize the order of train data when fitting.\n",
        "            Can be seeded with np.random.seed() prior to calling fit.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        None\n",
        "            Fits the SOM to the given data but does not return anything.\n",
        "        \"\"\"\n",
        "        # Count total number of iterations\n",
        "        global_iter_counter = 0\n",
        "        n_samples = X.shape[0]\n",
        "        total_iterations = np.minimum(epochs * n_samples, self.max_iter)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Break if past max number of iterations\n",
        "            if global_iter_counter > self.max_iter:\n",
        "                break\n",
        "\n",
        "            if shuffle:\n",
        "                rng = np.random.default_rng(self.random_state)\n",
        "                indices = rng.permutation(n_samples)\n",
        "            else:\n",
        "                indices = np.arange(n_samples)\n",
        "\n",
        "            # Train\n",
        "            for idx in indices:\n",
        "                # Break if past max number of iterations\n",
        "                if global_iter_counter > self.max_iter:\n",
        "                    break\n",
        "                input = X[idx]\n",
        "                # Do one step of training\n",
        "                self.step(input)\n",
        "                # Update learning rate\n",
        "                global_iter_counter += 1\n",
        "                self.lr = (1 - (global_iter_counter / total_iterations)) * self.initial_lr\n",
        "\n",
        "        # Compute inertia\n",
        "        inertia = np.sum(np.array([float(self._compute_point_intertia(x)) for x in X]))\n",
        "        self._inertia_ = inertia\n",
        "\n",
        "        # Set n_iter_ attribute\n",
        "        self._n_iter_ = global_iter_counter\n",
        "\n",
        "        # Set trained flag\n",
        "        self._trained = True\n",
        "\n",
        "        return\n",
        "\n",
        "    def fit_snap(self, X, t, epochs=1, shuffle=True, snap_step= 10):\n",
        "        # Count total number of iterations\n",
        "        global_iter_counter = 0\n",
        "        snap_list = []\n",
        "        n_samples = X.shape[0]\n",
        "        total_iterations = np.minimum(epochs * n_samples, self.max_iter)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Break if past max number of iterations\n",
        "            if global_iter_counter > self.max_iter:\n",
        "                break\n",
        "\n",
        "            if shuffle:\n",
        "                rng = np.random.default_rng(self.random_state)\n",
        "                indices = rng.permutation(n_samples)\n",
        "            else:\n",
        "                indices = np.arange(n_samples)\n",
        "\n",
        "            # Train\n",
        "            for idx in indices:\n",
        "                # Break if past max number of iterations\n",
        "                if global_iter_counter > self.max_iter:\n",
        "                    break\n",
        "                input = X[idx]\n",
        "                # Do one step of training\n",
        "                self.step(input)\n",
        "                # Update learning rate\n",
        "                global_iter_counter += 1\n",
        "                self.lr = (1 - (global_iter_counter / total_iterations)) * self.initial_lr\n",
        "\n",
        "            if epoch % snap_step == 0:\n",
        "                  newDic = get_labeledDic(self, X, t)\n",
        "                  pathi = '/content/SynthesisEmotions/snapshots/expression_map_step_' + str(global_iter_counter) +'.png'\n",
        "                  #print(global_iter_counter)\n",
        "                  draw_labeled_neurons_map(self, newDic,pathi,  'png')\n",
        "\n",
        "                  #print(global_iter_counter)\n",
        "                  #print(self.weights)\n",
        "                  #snap_list.append(self.weights)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Compute inertia\n",
        "        inertia = np.sum(np.array([float(self._compute_point_intertia(x)) for x in X]))\n",
        "        self._inertia_ = inertia\n",
        "\n",
        "        # Set n_iter_ attribute\n",
        "        self._n_iter_ = global_iter_counter\n",
        "\n",
        "        # Set trained flag\n",
        "        self._trained = True\n",
        "\n",
        "        return snap_list\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict cluster for each element in X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray\n",
        "            An ndarray of shape (n, self.dim) where n is the number of samples.\n",
        "            The data to predict clusters for.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        labels : ndarray\n",
        "            An ndarray of shape (n,). The predicted cluster index for each item\n",
        "            in X.\n",
        "        \"\"\"\n",
        "        # Check to make sure SOM has been fit\n",
        "        if not self._trained:\n",
        "            raise NotImplementedError('SOM2 object has no predict() method until after calling fit().')\n",
        "\n",
        "        # Make sure X has proper shape\n",
        "        assert len(X.shape) == 2, f'X should have two dimensions, not {len(X.shape)}'\n",
        "        assert X.shape[1] == self.dim, f'This SOM2 has dimention {self.dim}. Received input with dimension {X.shape[1]}'\n",
        "\n",
        "        labels = np.array([self._find_bmu(x) for x in X])\n",
        "        return labels\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transform the data X into cluster distance space.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray\n",
        "            Data of shape (n, self.dim) where n is the number of samples. The\n",
        "            data to transform.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        transformed : ndarray\n",
        "            Transformed data of shape (n, self.n*self.m). The Euclidean distance\n",
        "            from each item in X to each cluster center.\n",
        "        \"\"\"\n",
        "        # Stack data and cluster centers\n",
        "        X_stack = np.stack([X]*(self.m*self.n), axis=1)\n",
        "        cluster_stack = np.stack([self.weights]*X.shape[0], axis=0)\n",
        "\n",
        "        # Compute difference\n",
        "        diff = X_stack - cluster_stack\n",
        "\n",
        "        # Take and return norm\n",
        "        return np.linalg.norm(diff, axis=2)\n",
        "\n",
        "    def fit_predict(self, X, **kwargs):\n",
        "        \"\"\"\n",
        "        Convenience method for calling fit(X) followed by predict(X).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray\n",
        "            Data of shape (n, self.dim). The data to fit and then predict.\n",
        "        **kwargs\n",
        "            Optional keyword arguments for the .fit() method.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        labels : ndarray\n",
        "            ndarray of shape (n,). The index of the predicted cluster for each\n",
        "            item in X (after fitting the SOM2 to the data in X).\n",
        "        \"\"\"\n",
        "        # Fit to data\n",
        "        self.fit(X, **kwargs)\n",
        "\n",
        "        # Return predictions\n",
        "        return self.predict(X)\n",
        "\n",
        "    def fit_transform(self, X, **kwargs):\n",
        "        \"\"\"\n",
        "        Convenience method for calling fit(X) followed by transform(X). Unlike\n",
        "        in sklearn, this is not implemented more efficiently (the efficiency is\n",
        "        the same as calling fit(X) directly followed by transform(X)).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray\n",
        "            Data of shape (n, self.dim) where n is the number of samples.\n",
        "        **kwargs\n",
        "            Optional keyword arguments for the .fit() method.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        transformed : ndarray\n",
        "            ndarray of shape (n, self.m*self.n). The Euclidean distance\n",
        "            from each item in X to each cluster center.\n",
        "        \"\"\"\n",
        "        # Fit to data\n",
        "        self.fit(X, **kwargs)\n",
        "\n",
        "        # Return points in cluster distance space\n",
        "        return self.transform(X)\n",
        "\n",
        "    @property\n",
        "    def cluster_centers_(self):\n",
        "        return self.weights.reshape(self.m, self.n, self.dim)\n",
        "\n",
        "    @property\n",
        "    def inertia_(self):\n",
        "        if self._inertia_ is None:\n",
        "            raise AttributeError('SOM2 does not have inertia until after calling fit()')\n",
        "        return self._inertia_\n",
        "\n",
        "    @property\n",
        "    def n_iter_(self):\n",
        "        if self._n_iter_ is None:\n",
        "            raise AttributeError('SOM2 does not have n_iter_ attribute until after calling fit()')\n",
        "        return self._n_iter_"
      ],
      "metadata": {
        "id": "ysgUMQqL9xDi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}