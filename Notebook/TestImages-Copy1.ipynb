{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # NUMPY\n",
    "import pandas as pd # PANDAS\n",
    "import matplotlib.pyplot as plt # MATPLOTLIB\n",
    "import seaborn as sns # SEABORN\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "import os \n",
    "from skimage import filters\n",
    "from scipy import ndimage\n",
    "import math \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run auxfunctions.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a hacerlo para 1 secuencia. Luego veremos como hacerlo para varias\n",
    "#secuencias.\n",
    "#Objetivo. Tener los b_vectors, target_emotions para pasar al colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3614, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape_PCA\n",
    "\n",
    "\n",
    "my_data_forPCA = pd.read_csv('my_training_data_aligned_diff.csv',header = None)\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "scaled_landDiff = std_scaler.fit_transform(my_data_forPCA)\n",
    "scaled_landDiff.shape\n",
    "\n",
    "pca_shape = PCA(n_components=29)\n",
    "b_shape = pca_shape.fit_transform(scaled_landDiff)\n",
    "b_shape.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_labels = {}\n",
    "\n",
    "path_to_test_emotion ='/home/alicia/Documentos/Tesis2023/SynthesisEmotions/ck+copynew/Emotion_labels/Emotion/'\n",
    "\n",
    "series_test = glob.glob(path_to_test_emotion + '*/*/', recursive = True)\n",
    "series_select = series_test\n",
    "#series_select = np.random.choice(series_test, 20, replace=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(series_test)#hay algunas que no tienen tag de emocion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_select = np.sort(series_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(series_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_emotion = []\n",
    "path = 'ck+copynewTfile/transformed_test_images_total/'\n",
    "test_series = glob.glob(path + '*/*/', recursive = True)\n",
    "test_series = np.sort(test_series)\n",
    "path_to_test_emotion ='/home/alicia/Documentos/Tesis2023/SynthesisEmotions/ck+copynew/Emotion_labels/Emotion/'\n",
    "\n",
    "for i in np.sort(test_series):   \n",
    "    actual_subject = str(i).split('/')[2]\n",
    "    actual_subfolder = str(i).split('/')[3]\n",
    "    actual_serie = actual_subject + '/'+ actual_subfolder\n",
    "    \n",
    "    emo = os.listdir(path_to_test_emotion + actual_serie)[0]\n",
    "    emo_file = path_to_test_emotion + actual_serie + '/' + emo\n",
    "    with open(emo_file) as f:\n",
    "        emotion = int(float(f.readline()))\n",
    "        series_emotion.append(emotion)\n",
    "    \n",
    "    \n",
    "#print(series_emotion)\n",
    "#my_df = pd.DataFrame(series_emotion)\n",
    "#my_df.to_csv('ck+copynewTfile/series_test_total_targetemotions.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos por la shape feature\n",
    "\n",
    "\n",
    "series_emotion = []\n",
    "series = []\n",
    "\n",
    "#std_scaler_instance =  StandardScaler()\n",
    "for i in series_select:    \n",
    "    actual_subject = str(i).split('/')[9]\n",
    "    actual_subfolder = str(i).split('/')[10]\n",
    "    actual_serie = actual_subject + '/'+ actual_subfolder\n",
    "    emo = os.listdir(path_to_test_emotion + actual_serie)[0]\n",
    "    emo_file = path_to_test_emotion + actual_serie + '/' + emo\n",
    "    with open(emo_file) as f:\n",
    "        emotion = int(float(f.readline()))\n",
    "        series_emotion.append(emotion)\n",
    "    series.append(actual_serie)\n",
    "    \n",
    "serie_landmarks, shape_test_vector, serie_shape_data  = get_shape_features(series, pca_shape, std_scaler)\n",
    "#lo dejo asi, puede ser que requiera fit_transform. No sabemos.\n",
    "#Ver ambas maneras, por ahora transform (Fit csv con fit)\n",
    "x, y, z = shape_test_vector.shape\n",
    "\n",
    "a, b, c = serie_shape_data.shape\n",
    "shape_test_vector =shape_test_vector.reshape(x,z)\n",
    "serie_shape_data = serie_shape_data.reshape(a,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_df = pd.DataFrame(shape_test_vector)\n",
    "my_df.to_csv('ck+copynewTfile/pca_shapeTestingTotalnewTpoints_.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 68, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_landmarks[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Structure PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3614, 13)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_forPCA_structure = pd.read_csv('structure_feature_training_vector.csv',header = None)\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "scaled_landDiff = std_scaler.fit_transform(my_data_forPCA_structure)\n",
    "\n",
    "\n",
    "\n",
    "pca_struct = PCA(n_components=13)\n",
    "b_structure = pca_struct.fit_transform(scaled_landDiff)\n",
    "b_structure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_test_vector  = get_struct_features(series, pca_struct, std_scaler,serie_landmarks, serie_shape_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y,z = struct_test_vector.shape\n",
    "struct_test_vector =struct_test_vector.reshape(x,z)\n",
    "my_df = pd.DataFrame(struct_test_vector)\n",
    "my_df.to_csv('ck+copynewTfile/pca_structTestingTotalnewTpoints_.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos con Cartoon y Texture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 1, 13)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cartoon PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'im_newT_cartoonarray_.csv'\n",
    "chunk_size = 100\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size, header = None):\n",
    "    df_list.append(chunk)\n",
    "\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_forPCA_cartoon = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 168100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "scaled_landDiff = std_scaler.fit_transform(my_data_forPCA_cartoon)\n",
    "scaled_landDiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_cartoon = PCA(n_components=100)#era 14\n",
    "b_cartoon = pca_cartoon.fit_transform(scaled_landDiff)\n",
    "b_cartoon.shape # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S005/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S005/001/cartoonimg10.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S028/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S028/001/cartoonimg23.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S042/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S042/001/cartoonimg18.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S042/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S042/002/cartoonimg15.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S042/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S042/004/cartoonimg19.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S042/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S042/006/cartoonimg16.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S045/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S045/004/cartoonimg14.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S045/005/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S045/005/cartoonimg29.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S046/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S046/001/cartoonimg24.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S046/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S046/002/cartoonimg5.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S046/003/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S046/003/cartoonimg15.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S046/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S046/004/cartoonimg16.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S056/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S056/002/cartoonimg9.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S056/003/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S056/003/cartoonimg9.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S056/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S056/004/cartoonimg19.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S062/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S062/001/cartoonimg16.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S062/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S062/002/cartoonimg15.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S062/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S062/004/cartoonimg23.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S062/005/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S062/005/cartoonimg28.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S070/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S070/002/cartoonimg15.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S070/003/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S070/003/cartoonimg16.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S070/005/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S070/005/cartoonimg15.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S071/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S071/001/cartoonimg12.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S071/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S071/002/cartoonimg19.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S071/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S071/004/cartoonimg27.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S071/005/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S071/005/cartoonimg20.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S071/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S071/006/cartoonimg13.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S073/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S073/001/cartoonimg12.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S073/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S073/006/cartoonimg13.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S076/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S076/001/cartoonimg16.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S076/005/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S076/005/cartoonimg11.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S076/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S076/006/cartoonimg18.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S079/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S079/001/cartoonimg11.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S079/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S079/002/cartoonimg11.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S079/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S079/004/cartoonimg25.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S083/003/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S083/003/cartoonimg18.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S084/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S084/001/cartoonimg9.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S084/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S084/002/cartoonimg22.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S085/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S085/002/cartoonimg13.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S085/003/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S085/003/cartoonimg12.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S085/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S085/004/cartoonimg16.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S086/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S086/001/cartoonimg18.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S086/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S086/002/cartoonimg14.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S089/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S089/001/cartoonimg15.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S089/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S089/002/cartoonimg20.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S089/003/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S089/003/cartoonimg35.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S090/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S090/002/cartoonimg10.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S090/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S090/006/cartoonimg10.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S090/007/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S090/007/cartoonimg13.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S094/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S094/001/cartoonimg9.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S094/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S094/004/cartoonimg11.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S098/003/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S098/003/cartoonimg12.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S098/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S098/004/cartoonimg14.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S105/008/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S105/008/cartoonimg9.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S107/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S107/001/cartoonimg9.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S107/005/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S107/005/cartoonimg10.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S111/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S111/001/cartoonimg13.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S111/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S111/006/cartoonimg9.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S111/007/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S111/007/cartoonimg13.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S114/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S114/001/cartoonimg17.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S114/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S114/006/cartoonimg22.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S116/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S116/001/cartoonimg13.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S116/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S116/006/cartoonimg6.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S116/007/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S116/007/cartoonimg16.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S127/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S127/001/cartoonimg16.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S127/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S127/004/cartoonimg15.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S127/010/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S127/010/cartoonimg17.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S130/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S130/001/cartoonimg17.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S130/007/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S130/007/cartoonimg19.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S130/009/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S130/009/cartoonimg18.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S130/012/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S130/012/cartoonimg10.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S130/013/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S130/013/cartoonimg14.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S132/002/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S132/002/cartoonimg17.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S132/003/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S132/003/cartoonimg22.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S132/005/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S132/005/cartoonimg15.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S132/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S132/006/cartoonimg22.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S132/008/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S132/008/cartoonimg9.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S134/003/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S134/003/cartoonimg10.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S134/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S134/004/cartoonimg14.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S134/008/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S134/008/cartoonimg12.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S135/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S135/001/cartoonimg38.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S135/012/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S135/012/cartoonimg19.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S138/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S138/001/cartoonimg11.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S138/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S138/004/cartoonimg12.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S138/005/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S138/005/cartoonimg15.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S138/007/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S138/007/cartoonimg10.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S501/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S501/001/cartoonimg66.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S501/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S501/004/cartoonimg55.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S501/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S501/006/cartoonimg40.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S502/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S502/001/cartoonimg15.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S502/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S502/004/cartoonimg51.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S504/001/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S504/001/cartoonimg21.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S504/004/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S504/004/cartoonimg14.png']\n",
      "(410, 410)\n",
      "['ck+copynewTfile/cartoon_training_test_total/S504/006/cartoonimg0.png'\n",
      " 'ck+copynewTfile/cartoon_training_test_total/S504/006/cartoonimg17.png']\n"
     ]
    }
   ],
   "source": [
    "cartoon_test_vector  = get_cartoon_features(series, pca_cartoon, std_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y,z = cartoon_test_vector.shape\n",
    "cartoon_test_vector =cartoon_test_vector.reshape(x,z)\n",
    "my_df = pd.DataFrame(cartoon_test_vector)\n",
    "my_df.to_csv('ck+copynewTfile/pca_cartoonTestingToTalnewTpoints_.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 1, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'im_newT_texturearray_.csv'\n",
    "chunk_size = 100\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size, header = None):\n",
    "    df_list.append(chunk)\n",
    "\n",
    "df2 = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_forPCA_texture =df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 168100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "scaled_landDiff = std_scaler.fit_transform(my_data_forPCA_texture)\n",
    "scaled_landDiff.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 350)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_texture = PCA(n_components=350)#era 14\n",
    "b_texture = pca_texture.fit_transform(scaled_landDiff)\n",
    "b_texture.shape # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n",
      "(410, 410)\n"
     ]
    }
   ],
   "source": [
    "texture_test_vector  = get_texture_features(series, pca_texture, std_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y,z = texture_test_vector.shape\n",
    "texture_test_vector =texture_test_vector.reshape(x,z)\n",
    "my_df = pd.DataFrame(texture_test_vector)\n",
    "my_df.to_csv('ck+copynewTfile/pca_textureTestingTotalnewTpoints_.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1, 350)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texture_test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texture_features(series, pca, scaler):\n",
    "    texture_features = []    \n",
    "    for s in range(0, len(series)):\n",
    "        texture_f = get_texture_f(series[s], pca, scaler)        \n",
    "        texture_features.append(texture_f)        \n",
    "    texture_features = np.asarray(texture_features)\n",
    "    return texture_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_texture_f(s, pca, scaler):    \n",
    "    warpimgpath = 'ck+copynewTfile/transformed_test_images_total/' + s + '/'\n",
    "    imagepathfirst = warpimgpath +'/warped_image_procustres_'+ str(0) + '.png'\n",
    "    imagepath = warpimgpath +'/warped_image_procustres_'+ str(len(os.listdir(warpimgpath))-1) + '.png'\n",
    "    \n",
    "    img = cv2.imread(imagepath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = img[40:450, 170:580]\n",
    "    print(img2.shape)\n",
    "   \n",
    "    texture_e = \"ck+copynewTfile/texture_training_test_total/\" + s +\"/textureimg\"  + str(len(os.listdir(warpimgpath))-1) +\".png\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    imtext = []\n",
    "\n",
    "    texture_images = np.asarray([texture_e])\n",
    "    for i in texture_images:\n",
    "        img = cv2.imread(i, cv2.IMREAD_GRAYSCALE)    \n",
    "        imtext.append(img.flatten())\n",
    "    \n",
    "    imtextarray = np.asarray(imtext)  \n",
    "    \n",
    "\n",
    "    \n",
    "    test_texture_data = imtextarray.reshape(1,-1)    \n",
    "    scaled_inst = scaler.transform(test_texture_data)\n",
    "    b_texture_instance = pca.transform(scaled_inst)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return b_texture_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cartoon_features(series, pca, scaler):\n",
    "    cartoon_features = []    \n",
    "    for s in range(0, len(series)):\n",
    "        cartoon_f = get_cartoon_f(series[s], pca, scaler)        \n",
    "        cartoon_features.append(cartoon_f)        \n",
    "    cartoon_features = np.asarray(cartoon_features)\n",
    "    return cartoon_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_cartoon_f(s, pca, scaler):    \n",
    "    warpimgpath = 'ck+copynewTfile/transformed_test_images_total/' + s + '/'\n",
    "    imagepathfirst = warpimgpath +'/warped_image_procustres_'+ str(0) + '.png'\n",
    "    imagepath = warpimgpath +'/warped_image_procustres_'+ str(len(os.listdir(warpimgpath))-1) + '.png'\n",
    "    \n",
    "    img = cv2.imread(imagepath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = img[40:450, 170:580]\n",
    "    print(img2.shape)\n",
    "\n",
    "    if not os.path.exists(\"ck+copynewTfile/cartoon_training_test_total/\" + s):\n",
    "        # Create the directory\n",
    "        os.makedirs(\"ck+copynewTfile/cartoon_training_test_total/\"+ s)\n",
    "    if not os.path.exists(\"ck+copynewTfile/texture_training_test_total/\" + s):\n",
    "        # Create the directory\n",
    "        os.makedirs(\"ck+copynewTfile/texture_training_test_total/\" +s)\n",
    "        \n",
    "    #cartoon, texture = cartoonTexture_grey(img2, 0.2, 50, 0.35, 0.35, 1.0, 0)\n",
    "    #cv2.imwrite(\"ck+copynewTfile/cartoon_training_test_total/\" + s +\"/cartoonimg\" + str(len(os.listdir(warpimgpath))-1) +\".png\", cartoon)\n",
    "    #cv2.imwrite(\"ck+copynewTfile/texture_training_test_total/\"+ s +\"/textureimg\" + str(len(os.listdir(warpimgpath))-1)+\".png\", texture)\n",
    "    \n",
    "    #img = cv2.imread(imagepathfirst)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #img2 = img[40:450, 170:580]\n",
    "\n",
    "    #cartoon, texture = cartoonTexture_grey(img2, 0.2, 50, 0.35, 0.35, 1.0, 0)\n",
    "    #cv2.imwrite(\"ck+copynewTfile/cartoon_training_test_total/\" + s +\"/cartoonimg\" + str(0) +\".png\", cartoon)\n",
    "    #cv2.imwrite(\"ck+copynewTfile/texture_training_test_total/\" +s +\"/textureimg\" + str(0)+\".png\", texture)\n",
    "   \n",
    "    cartoon_f = \"ck+copynewTfile/cartoon_training_test_total/\" + s +\"/cartoonimg\" + str(0) +\".png\"\n",
    "    cartoon_e = \"ck+copynewTfile/cartoon_training_test_total/\" + s +\"/cartoonimg\" + str(len(os.listdir(warpimgpath))-1) +\".png\"\n",
    "    texture_e = \"ck+copynewTfile/texture_training_test_total/\" + s +\"/textureimg\"  + str(len(os.listdir(warpimgpath))-1) +\".png\"\n",
    "    \n",
    "    imcart = []\n",
    "    cartoon_images = np.asarray([cartoon_f, cartoon_e])\n",
    "    print(cartoon_images)\n",
    "    for i in cartoon_images:\n",
    "        img = cv2.imread(i, cv2.IMREAD_GRAYSCALE)\n",
    "        img_mean = img/np.mean(img)\n",
    "        imcart.append(img_mean.flatten())\n",
    "    \n",
    "    imcartoon = np.asarray(imcart)\n",
    "    imcartooncopy = []\n",
    "    for i in range(0, len(imcartoon) ):\n",
    "        imca = imcartoon[i] - imcartoon[0]\n",
    "        imcartooncopy.append(np.asarray(imca))\n",
    "\n",
    "    imcartoonarray = np.asarray(imcartooncopy)\n",
    "    \n",
    "    test_cartoon_data = imcartoonarray[1].reshape(1,-1)\n",
    "    \n",
    "    scaled_inst = scaler.transform(test_cartoon_data)\n",
    "    b_cartoon_instance = pca.transform(scaled_inst)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return  b_cartoon_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y,z = cartoon_test_vector.shape\n",
    "cartoon_test_vector =cartoon_test_vector.reshape(x,z)\n",
    "my_df = pd.DataFrame(cartoon_test_vector)\n",
    "my_df.to_csv('ck+copynewTfile/pca_cartoonTestingnewTpoints_.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_struct_features(series, pca, scaler, serie_landmarks, serie_shape_data):\n",
    "    struct_features = []    \n",
    "    for s in range(0, len(series)):\n",
    "        struct_f = get_struct_f(series[s], pca, scaler, serie_landmarks[s], serie_shape_data[s])        \n",
    "        struct_features.append(struct_f)        \n",
    "    struct_features = np.asarray(struct_features)\n",
    "    #serie_landmarks = np.asarray(serie_landmarks)\n",
    "    return struct_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_struct_f(s, pca, scaler, one_serie_landmark, serie_data):\n",
    "    pathi = 'ck+copynewTfile/transformed_test_images_total/' + s + '/'\n",
    "    firsti = pathi + '/' +np.sort(os.listdir(pathi))[0]    \n",
    "    first_frame = np.asarray([one_serie_landmark[0]])    \n",
    "    first_images = np.asarray([firsti])\n",
    "    struct_test = get_21_points(first_frame, first_images)\n",
    "    last_point = get_emotion_intensity(my_data_forPCA, serie_data)\n",
    "    structre_test_f =np.append(struct_test,last_point )\n",
    "    \n",
    "    test_struc_data = structre_test_f.reshape(1,-1)    \n",
    "    scaled_inst = scaler.transform(test_struc_data)\n",
    "    \n",
    "\n",
    "    b_structure_instance = pca.transform(scaled_inst)\n",
    "    \n",
    "    return b_structure_instance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 136)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_shape_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_intensity(my_data_forPCA, serie_shape_data):\n",
    "    Ai = my_data_forPCA.max()\n",
    "    data_2_intensity_div = serie_shape_data.flatten()/Ai\n",
    "    data_2_intensity_sum =  np.sum(data_2_intensity_div)\n",
    "    data_2_intensity_final = data_2_intensity_sum/136\n",
    "    return data_2_intensity_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_21_points(first_frame, first_images ):\n",
    "    first_feature_point = list_get_feature_point(first_frame, 1, first_images)\n",
    "    second_feature_point = list_get_feature_point(first_frame, 2, first_images)\n",
    "    third_feature_point = list_get_feature_point(first_frame, 3, first_images)\n",
    "    fourth_feature_point = list_get_feature_point(first_frame, 4, first_images)\n",
    "    five_feature_point = list_get_feature_point(first_frame, 5, first_images)\n",
    "    six_feature_point = list_get_feature_point(first_frame, 6, first_images)\n",
    "    seven_feature_point = list_get_feature_point(first_frame, 7, first_images)\n",
    "    eight_feature_point = list_get_feature_point(first_frame, 8, first_images)\n",
    "    nine_feature_point = list_get_feature_point(first_frame, 9, first_images)\n",
    "    ten_feature_point = list_get_feature_point(first_frame, 10, first_images)\n",
    "    eleven_feature_point = list_get_feature_point(first_frame, 11, first_images)\n",
    "    twelve_feature_point = list_get_feature_point(first_frame, 12, first_images)\n",
    "    thirteen_feature_point = list_get_feature_point(first_frame, 13, first_images)\n",
    "    fourteen_feature_point = list_get_feature_point(first_frame, 14, first_images)\n",
    "    fifteen_feature_point = list_get_feature_point(first_frame, 15, first_images)\n",
    "    sixteen_feature_point = list_get_feature_point(first_frame, 16, first_images)\n",
    "    seventeen_feature_point = list_get_feature_point(first_frame, 17, first_images)\n",
    "    eigtheen_feature_point = list_get_feature_point(first_frame, 18, first_images)\n",
    "    nineteen_feature = list_get_feature_point(first_frame, 19, first_images)\n",
    "    twenty_feature = list_get_feature_point(first_frame, 20, first_images)\n",
    "    twentyone_feature = list_get_feature_point(first_frame, 21, first_images)\n",
    "    \n",
    "    structure_vector = first_feature_point\n",
    "    structure_vector = np.vstack((structure_vector, second_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, third_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, fourth_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, five_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, six_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, seven_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, eight_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, nine_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, ten_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, eleven_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, twelve_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, thirteen_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, fourteen_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, fifteen_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, sixteen_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, seventeen_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, eigtheen_feature_point))\n",
    "    structure_vector = np.vstack((structure_vector, nineteen_feature))\n",
    "    structure_vector = np.vstack((structure_vector, twenty_feature))\n",
    "    structure_vector = np.vstack((structure_vector, twentyone_feature))\n",
    "    \n",
    "    structre_features = np.asarray(structure_vector).flatten().T\n",
    "    return structre_features\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_shape = pd.read_csv('pca_training_shapepoints_newT.csv',header = None)\n",
    "#b_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_shape = pd.read_csv('pca_shapepoints.csv',header = None)\n",
    "#b_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#landmarks, shape_fea = get_shape_features(series[0:2], pca_shape, std_scaler_instance )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 68, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#landmarks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31761163e-17, -8.46133663e-17,  1.02522191e-17,\n",
       "         2.48999310e-17, -5.92633616e-17, -4.21758387e-17,\n",
       "        -2.74159661e-19,  6.97939031e-18,  8.07992736e-18,\n",
       "         5.94490542e-17,  3.24739899e-17,  2.06684422e-18,\n",
       "         3.24723444e-17, -5.74443291e-17, -3.32178148e-17,\n",
       "        -1.45244305e-17, -2.78273743e-17,  4.35890223e-17,\n",
       "        -6.63422246e-18,  1.71194123e-17,  1.14750728e-17,\n",
       "         4.42816110e-17,  7.95650766e-17, -5.73616061e-17,\n",
       "        -8.13343645e-18, -4.56504349e-17, -1.32944873e-17,\n",
       "        -8.27537852e-18,  3.10928033e-17],\n",
       "       [ 1.31761163e-17, -8.46133663e-17,  1.02522191e-17,\n",
       "         2.48999310e-17, -5.92633616e-17, -4.21758387e-17,\n",
       "        -2.74159661e-19,  6.97939031e-18,  8.07992736e-18,\n",
       "         5.94490542e-17,  3.24739899e-17,  2.06684422e-18,\n",
       "         3.24723444e-17, -5.74443291e-17, -3.32178148e-17,\n",
       "        -1.45244305e-17, -2.78273743e-17,  4.35890223e-17,\n",
       "        -6.63422246e-18,  1.71194123e-17,  1.14750728e-17,\n",
       "         4.42816110e-17,  7.95650766e-17, -5.73616061e-17,\n",
       "        -8.13343645e-18, -4.56504349e-17, -1.32944873e-17,\n",
       "        -8.27537852e-18,  3.10928033e-17]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape_fea.reshape(2,29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_features(series, pca, scaler):\n",
    "    shape_features = []\n",
    "    serie_landmarks = []\n",
    "    serie_shape_data = []\n",
    "    for s in series:\n",
    "        feature_landmarks, shape_f, test_s_data = get_shape_f(s, pca, scaler)        \n",
    "        shape_features.append(shape_f)\n",
    "        serie_landmarks.append(feature_landmarks)\n",
    "        serie_shape_data.append(test_s_data)\n",
    "    shape_features = np.asarray(shape_features)\n",
    "    serie_shape_data = np.asarray(serie_shape_data)\n",
    "    return serie_landmarks, shape_features, serie_shape_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_f(serie, pca,scaler):\n",
    "    image_path =  '/home/alicia/Documentos/Tesis2023/SynthesisEmotions/ck+copynew/extended-cohn-kanade-images/cohn-kanade-images/' + serie\n",
    "    land_path = '/home/alicia/Documentos/Tesis2023/SynthesisEmotions/ck+copynew/Landmarks/' + serie\n",
    "    \n",
    "    test_images = []\n",
    "    test_land = []\n",
    "    \n",
    "    files = Path(image_path).rglob(\"*\")\n",
    "    for file in files:\n",
    "        if len(os.path.normpath(file).split(os.path.sep)[11].split('_')) == 3:\n",
    "            test_images.append(str(file))\n",
    "            \n",
    "    files = Path(land_path).rglob(\"*\")\n",
    "    for file in files:\n",
    "        if len(os.path.normpath(file).split(os.path.sep)[10].split('_')) == 4:\n",
    "            test_land.append(str(file))\n",
    "    \n",
    "    test_images = np.sort(test_images)\n",
    "    test_land = np.sort(test_land)\n",
    "    \n",
    "    transformed_landmarks_total, test_shape_data = get_test_shape_data(test_images, test_land, serie)\n",
    "    test_shape_data = test_shape_data.reshape(1,-1)\n",
    "    \n",
    "    scaled_inst = scaler.transform(test_shape_data)\n",
    "    b_shape_instance = pca.transform(scaled_inst)  \n",
    "    \n",
    "    return transformed_landmarks_total, b_shape_instance, test_shape_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'std_scaler_instance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_shape_f(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS005/001\u001b[39m\u001b[38;5;124m'\u001b[39m, pca_shape, \u001b[43mstd_scaler_instance\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'std_scaler_instance' is not defined"
     ]
    }
   ],
   "source": [
    "get_shape_f('S005/001', pca_shape, std_scaler_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_shape_data(test_images, test_land, serie):\n",
    "    landmarks_seqXY = get_landmarks_of_folder(test_land)\n",
    "    cant_de_frames = len(landmarks_seqXY)\n",
    "    intercalated_data = intercalate_data_of_vectors(landmarks_seqXY, 0)\n",
    "    pathi = 'ck+copynewTfile/transformed_test_images_total/' + serie + '/'\n",
    "    \n",
    "    if not os.path.exists(pathi):\n",
    "        # Create the directory\n",
    "        os.makedirs(pathi)\n",
    "    reference_image_path = 'ck+copynewTfile/reference_image.png'\n",
    "    my_landmark_for_ref = pd.read_csv('ck+copynewTfile/cknewT_landmark_intercalated_data.csv',header = None)\n",
    "    reference_land = my_landmark_for_ref.iloc[0]\n",
    "    transformed_landmarks_total = align_and_transform_vector_of_images(reference_image_path, reference_land, intercalated_data, test_images, pathi)\n",
    "    transformed_final = transformed_landmarks_total[0].flatten('F')\n",
    "    for i in range (1, len(transformed_landmarks_total)):\n",
    "        transformed_final = np.vstack((transformed_final, transformed_landmarks_total[i].flatten('F')))\n",
    "    nd =0\n",
    "    my_data_aligned_diff =[]\n",
    "    for i in range(0, cant_de_frames):#51\n",
    "        my_data_aligned_diff.append(transformed_final[i]- transformed_final[0]) #no dice nada de abs\n",
    "    my_data_aligned_diff = np.asarray(my_data_aligned_diff)\n",
    "\n",
    "    test_shape_data = my_data_aligned_diff[len(my_data_aligned_diff) -1]\n",
    "    return transformed_landmarks_total, test_shape_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_images = []\n",
    "\n",
    "\n",
    "\n",
    "image_path = '/home/alicia/Documentos/Tesis2023/SynthesisEmotions/ck+copynew/extended-cohn-kanade-images/cohn-kanade-images/S005/001'\n",
    "files = Path(image_path).rglob(\"*\")\n",
    "for file in files:\n",
    "    if len(os.path.normpath(file).split(os.path.sep)[11].split('_')) == 3:        \n",
    "        test_images.append(str(file))\n",
    "\n",
    "emo_file = '/home/alicia/Documentos/Tesis2023/SynthesisEmotions/ck+copynew/Emotion_labels/Emotion/S005/001/S005_001_00000011_emotion.txt'\n",
    "\n",
    "with open(emo_file) as f:\n",
    "  emotion = int(float(f.readline()))\n",
    "  test_images_labels[0] = emotion\n",
    "\n",
    "land_files  = []\n",
    "\n",
    "image_path = '/home/alicia/Documentos/Tesis2023/SynthesisEmotions/ck+copynew/Landmarks/S005/001'\n",
    "files = Path(image_path).rglob(\"*\")\n",
    "for file in files:    \n",
    "    if len(os.path.normpath(file).split(os.path.sep)[10].split('_')) == 4:\n",
    "        land_files.append(str(file))\n",
    "\n",
    "\n",
    "test_images = np.sort(test_images)\n",
    "land_files = np.sort(land_files)\n",
    "len(land_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "landmarks_seqXY = get_landmarks_of_folder(land_files)\n",
    "cant_de_frames = len(landmarks_seqXY)\n",
    "cant_de_frames\n",
    "intercalated_data = intercalate_data_of_vectors(landmarks_seqXY, 0)\n",
    "pathi = 'ck+copynewTfile/transformed_test_total_images/'\n",
    "\n",
    "if not os.path.exists(pathi):\n",
    "    # Create the directory\n",
    "    os.makedirs(pathi)\n",
    "reference_image_path = 'ck+copynewTfile/reference_image.png'\n",
    "my_landmark_for_ref = pd.read_csv('ck+copynewTfile/cknewT_landmark_intercalated_data.csv',header = None)\n",
    "reference_land = my_landmark_for_ref.iloc[0]\n",
    "transformed_landmarks_total = align_and_transform_vector_of_images(reference_image_path, reference_land, intercalated_data, test_images, pathi)\n",
    "\n",
    "transformed_final = transformed_landmarks_total[0].flatten('F')\n",
    "for i in range (1, len(transformed_landmarks_total)):\n",
    "    transformed_final = np.vstack((transformed_final, transformed_landmarks_total[i].flatten('F')))\n",
    "\n",
    "\n",
    "nd =0\n",
    "my_data_aligned_diff =[]\n",
    "for i in range(0, cant_de_frames):#51\n",
    "    my_data_aligned_diff.append(transformed_final[i]- transformed_final[0]) #no dice nada de abs\n",
    "my_data_aligned_diff = np.asarray(my_data_aligned_diff)\n",
    "\n",
    "test_shape_data = my_data_aligned_diff[len(my_data_aligned_diff) -1]\n",
    "#PCA DEBAJO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 136)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora hacemos PCA con este vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3614, 29)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "my_data_forPCA = pd.read_csv('my_training_data_aligned_diff.csv',header = None)\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "scaled_landDiff = std_scaler.fit_transform(my_data_forPCA)\n",
    "scaled_landDiff.shape\n",
    "\n",
    "pca_shape = PCA(n_components=29)\n",
    "b_shape = pca_shape.fit_transform(scaled_landDiff)\n",
    "b_shape.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 136)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_shape_data = test_shape_data.reshape(1,-1)\n",
    "std_scaler_instance =  StandardScaler()\n",
    "scaled_inst = std_scaler_instance.fit_transform(test_shape_data)\n",
    "scaled_inst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 29)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_shape_instance = pca_shape.transform(scaled_inst)\n",
    "b_shape_instance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora vamos con structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 68, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_landmarks_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_landmarks_total.shape # necesitamos los landmarks en [x, y]\n",
    "\n",
    "\n",
    "firsti = pathi + '/' +np.sort(os.listdir(pathi))[0]\n",
    "\n",
    "first_frame = np.asarray([transformed_landmarks_total[0]])\n",
    "first_images = np.asarray([firsti])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_feature_point = list_get_feature_point(first_frame, 1, first_images)\n",
    "second_feature_point = list_get_feature_point(first_frame, 2, first_images)\n",
    "third_feature_point = list_get_feature_point(first_frame, 3, first_images)\n",
    "fourth_feature_point = list_get_feature_point(first_frame, 4, first_images)\n",
    "five_feature_point = list_get_feature_point(first_frame, 5, first_images)\n",
    "six_feature_point = list_get_feature_point(first_frame, 6, first_images)\n",
    "seven_feature_point = list_get_feature_point(first_frame, 7, first_images)\n",
    "eight_feature_point = list_get_feature_point(first_frame, 8, first_images)\n",
    "nine_feature_point = list_get_feature_point(first_frame, 9, first_images)\n",
    "ten_feature_point = list_get_feature_point(first_frame, 10, first_images)\n",
    "eleven_feature_point = list_get_feature_point(first_frame, 11, first_images)\n",
    "twelve_feature_point = list_get_feature_point(first_frame, 12, first_images)\n",
    "thirteen_feature_point = list_get_feature_point(first_frame, 13, first_images)\n",
    "fourteen_feature_point = list_get_feature_point(first_frame, 14, first_images)\n",
    "fifteen_feature_point = list_get_feature_point(first_frame, 15, first_images)\n",
    "sixteen_feature_point = list_get_feature_point(first_frame, 16, first_images)\n",
    "seventeen_feature_point = list_get_feature_point(first_frame, 17, first_images)\n",
    "eigtheen_feature_point = list_get_feature_point(first_frame, 18, first_images)\n",
    "nineteen_feature = list_get_feature_point(first_frame, 19, first_images)\n",
    "twenty_feature = list_get_feature_point(first_frame, 20, first_images)\n",
    "twentyone_feature = list_get_feature_point(first_frame, 21, first_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_vector = first_feature_point\n",
    "structure_vector = np.vstack((structure_vector, second_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, third_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, fourth_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, five_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, six_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, seven_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, eight_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, nine_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, ten_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, eleven_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, twelve_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, thirteen_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, fourteen_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, fifteen_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, sixteen_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, seventeen_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, eigtheen_feature_point))\n",
    "structure_vector = np.vstack((structure_vector, nineteen_feature))\n",
    "structure_vector = np.vstack((structure_vector, twenty_feature))\n",
    "structure_vector = np.vstack((structure_vector, twentyone_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structre_features = np.asarray(structure_vector).flatten().T\n",
    "structre_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ai = my_data_forPCA.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.13044903e+00],\n",
       "       [-2.09843077e+00],\n",
       "       [-2.04936478e+00],\n",
       "       [-1.80733321e+00],\n",
       "       [-1.54617137e+00],\n",
       "       [ 3.92520230e-01],\n",
       "       [ 9.29445312e-01],\n",
       "       [ 2.00847281e-01],\n",
       "       [ 7.89640622e-01],\n",
       "       [ 1.89898945e-01],\n",
       "       [-3.19994025e-01],\n",
       "       [-7.59037758e-01],\n",
       "       [ 5.06418766e-01],\n",
       "       [ 5.06728188e+00],\n",
       "       [ 3.21106435e+00],\n",
       "       [ 2.77136044e+00],\n",
       "       [ 2.73026498e+00],\n",
       "       [-1.38520767e+00],\n",
       "       [ 4.29521874e-01],\n",
       "       [ 5.36783258e-01],\n",
       "       [ 1.83214475e-01],\n",
       "       [-2.46329583e+00],\n",
       "       [-2.14251240e+00],\n",
       "       [-3.82483246e+00],\n",
       "       [-2.27591092e+00],\n",
       "       [ 3.04810214e-01],\n",
       "       [ 2.18522220e+00],\n",
       "       [ 1.51464518e+00],\n",
       "       [ 7.03510862e-01],\n",
       "       [ 5.97880833e-01],\n",
       "       [-2.29652546e+00],\n",
       "       [-1.23195424e+00],\n",
       "       [-1.45015848e+00],\n",
       "       [-7.33942067e-01],\n",
       "       [ 1.26826281e+00],\n",
       "       [ 2.18496909e+00],\n",
       "       [-1.13695468e+00],\n",
       "       [-2.81604531e+00],\n",
       "       [-4.32888512e+00],\n",
       "       [-3.43374360e+00],\n",
       "       [-2.58797303e+00],\n",
       "       [-1.72462079e+00],\n",
       "       [ 4.51910572e+00],\n",
       "       [ 6.78864746e+00],\n",
       "       [ 5.80091203e+00],\n",
       "       [ 5.33328776e+00],\n",
       "       [ 4.21833767e+00],\n",
       "       [ 4.40795413e+00],\n",
       "       [-5.42078202e-02],\n",
       "       [-3.47154679e+00],\n",
       "       [-1.40501428e+00],\n",
       "       [-1.22020052e+00],\n",
       "       [-7.10030680e-01],\n",
       "       [ 6.12529964e-01],\n",
       "       [-1.93965345e+00],\n",
       "       [-1.13485115e-02],\n",
       "       [ 2.52238995e-01],\n",
       "       [ 3.70027219e-01],\n",
       "       [-1.28122011e-01],\n",
       "       [-5.72124382e-01],\n",
       "       [-1.27774086e-01],\n",
       "       [-1.91408849e-01],\n",
       "       [-7.00096455e-01],\n",
       "       [-1.17672894e+00],\n",
       "       [-1.56117928e+00],\n",
       "       [-1.01727829e+00],\n",
       "       [-2.08684467e-01],\n",
       "       [ 3.81372494e-02],\n",
       "       [ 6.04048748e-01],\n",
       "       [ 1.21548830e+00],\n",
       "       [ 1.47368554e+00],\n",
       "       [ 2.02559918e+00],\n",
       "       [ 2.58826100e+00],\n",
       "       [ 1.60082911e+00],\n",
       "       [ 1.54794539e+00],\n",
       "       [ 3.82656927e+00],\n",
       "       [ 3.81647322e+00],\n",
       "       [ 9.80948013e-01],\n",
       "       [-1.19322381e+00],\n",
       "       [-1.94276128e+00],\n",
       "       [-8.13800428e-01],\n",
       "       [ 6.38807194e-01],\n",
       "       [ 4.54207633e-01],\n",
       "       [ 4.61504317e-01],\n",
       "       [ 2.23435692e-01],\n",
       "       [-2.21833614e+00],\n",
       "       [ 1.17049689e+00],\n",
       "       [ 3.51426404e+00],\n",
       "       [ 5.06056925e+00],\n",
       "       [ 9.42372080e+00],\n",
       "       [ 1.48182861e+01],\n",
       "       [ 7.21742940e+00],\n",
       "       [ 4.07885343e+00],\n",
       "       [-6.06784368e-01],\n",
       "       [-5.65704580e-01],\n",
       "       [ 4.88596733e+00],\n",
       "       [ 5.14427616e+00],\n",
       "       [ 5.44509021e+00],\n",
       "       [ 5.94388282e+00],\n",
       "       [-6.59534909e+00],\n",
       "       [-3.80629915e+00],\n",
       "       [-1.53243012e+00],\n",
       "       [-2.58392840e+00],\n",
       "       [-5.69311074e+00],\n",
       "       [ 3.53566180e-01],\n",
       "       [ 1.50447834e+00],\n",
       "       [ 3.13652905e+00],\n",
       "       [-1.93783127e+00],\n",
       "       [-3.79315602e+00],\n",
       "       [-4.18085883e+00],\n",
       "       [-1.05978190e+00],\n",
       "       [ 3.80578061e+00],\n",
       "       [ 2.61358595e+00],\n",
       "       [-2.37373355e-01],\n",
       "       [-5.21511251e+00],\n",
       "       [-6.27462460e+00],\n",
       "       [-3.35883515e+00],\n",
       "       [-6.76240668e+00],\n",
       "       [-3.39177984e+00],\n",
       "       [-2.25183066e+00],\n",
       "       [-1.37288057e+00],\n",
       "       [-4.48074547e+00],\n",
       "       [-2.07535851e+00],\n",
       "       [-1.13837304e+00],\n",
       "       [-9.14720050e-01],\n",
       "       [-2.15955122e+00],\n",
       "       [-2.79215915e+00],\n",
       "       [-2.60567822e+00],\n",
       "       [-1.91855215e+00],\n",
       "       [-1.92828240e+00],\n",
       "       [-2.48761449e+00],\n",
       "       [-1.58299619e+00],\n",
       "       [-1.60213037e+00],\n",
       "       [-1.58636335e+00],\n",
       "       [-2.97546047e+00],\n",
       "       [-1.93839462e+00]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_shape_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_shape_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_shape_data\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_shape_data' is not defined"
     ]
    }
   ],
   "source": [
    "test_shape_data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ai.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.020026992286394683"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_2_intensity_div = test_shape_data.flatten()/Ai\n",
    "data_2_intensity_sum =  np.sum(data_2_intensity_div)\n",
    "data_2_intensity_final = data_2_intensity_sum/136\n",
    "data_2_intensity_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotionIn = data_2_intensity_final\n",
    "structre_features =np.append(structre_features,emotionIn )\n",
    "structre_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora hacemos PCA de estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3614, 13)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_forPCA_structure = pd.read_csv('structure_feature_training_vector.csv',header = None)\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "scaled_landDiff = std_scaler.fit_transform(my_data_forPCA_structure)\n",
    "\n",
    "\n",
    "\n",
    "pca_structure = PCA(n_components=13)\n",
    "b_structure = pca_structure.fit_transform(scaled_landDiff)\n",
    "b_structure.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_struc_data = structre_features.reshape(1,-1)\n",
    "std_scaler_instance =  StandardScaler()\n",
    "scaled_inst = std_scaler_instance.fit_transform(test_struc_data)\n",
    "test_struc_data.shape\n",
    "\n",
    "b_structure_instance = pca_structure.transform(test_struc_data)\n",
    "b_structure_instance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos por el cartoon y la textura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 410)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warpimgpath = 'ck+copynewTfile/transformed_test_images'\n",
    "\n",
    "imagepathfirst = warpimgpath +'/warped_image_procustres_'+ str(0) + '.png'\n",
    "imagepath = warpimgpath +'/warped_image_procustres_'+ str(len(os.listdir(warpimgpath))-1) + '.png'\n",
    "\n",
    "img = cv2.imread(imagepath)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img2 = img[40:450, 170:580]\n",
    "print(img2.shape)\n",
    "\n",
    "if not os.path.exists(\"ck+copynewTfile/cartoon_training_test\"):\n",
    "    # Create the directory\n",
    "    os.makedirs(\"ck+copynewTfile/cartoon_training_test\")\n",
    "if not os.path.exists(\"ck+copynewTfile/texture_training_test\"):\n",
    "    # Create the directory\n",
    "    os.makedirs(\"ck+copynewTfile/texture_training_test\")\n",
    "\n",
    "\n",
    "\n",
    "cartoon, texture = cartoonTexture_grey(img2, 0.2, 50, 0.35, 0.35, 1.0, 0)\n",
    "cv2.imwrite(\"ck+copynewTfile/cartoon_training_test/cartoonimg\" + str(len(os.listdir(warpimgpath))-1) +\".png\", cartoon)\n",
    "cv2.imwrite(\"ck+copynewTfile/texture_training_test/textureimg\" + str(len(os.listdir(warpimgpath))-1)+\".png\", texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(imagepathfirst)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img2 = img[40:450, 170:580]\n",
    "\n",
    "cartoon, texture = cartoonTexture_grey(img2, 0.2, 50, 0.35, 0.35, 1.0, 0)\n",
    "cv2.imwrite(\"ck+copynewTfile/cartoon_training_test/cartoonimg\" + str(0) +\".png\", cartoon)\n",
    "cv2.imwrite(\"ck+copynewTfile/texture_training_test/textureimg\" + str(0)+\".png\", texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartoon_f = \"ck+copynewTfile/cartoon_training_test/cartoonimg\" + str(0) +\".png\"\n",
    "cartoon_e = \"ck+copynewTfile/cartoon_training_test/cartoonimg\" + str(len(os.listdir(warpimgpath))-1) +\".png\"\n",
    "texture_e = \"ck+copynewTfile/texture_training_test/textureimg\"  + str(len(os.listdir(warpimgpath))-1) +\".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imcart = []\n",
    "cartoon_images = np.asarray([cartoon_f, cartoon_e])\n",
    "\n",
    "for i in cartoon_images:\n",
    "    img = cv2.imread(i, cv2.IMREAD_GRAYSCALE)\n",
    "    img_mean = img/np.mean(img)\n",
    "    imcart.append(img_mean.flatten())\n",
    "    \n",
    "imcartoon = np.asarray(imcart)\n",
    "imcartooncopy = []\n",
    "for i in range(0, len(imcartoon) ):\n",
    "    imca = imcartoon[i] - imcartoon[0]\n",
    "    imcartooncopy.append(np.asarray(imca))\n",
    "\n",
    "imcartoonarray = np.asarray(imcartooncopy)\n",
    "imcartoonarray.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 168100)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imtext = []\n",
    "\n",
    "texture_images = np.asarray([texture_e])\n",
    "for i in texture_images:\n",
    "    img = cv2.imread(i, cv2.IMREAD_GRAYSCALE)    \n",
    "    imtext.append(img.flatten())\n",
    "    \n",
    "imtextarray = np.asarray(imtext)\n",
    "imtextarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cartoon PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'im_newT_cartoonarray_.csv'\n",
    "chunk_size = 100\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size, header = None):\n",
    "    df_list.append(chunk)\n",
    "\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_forPCA = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 168100)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "std_scaler = StandardScaler()\n",
    "scaled_landDiff = std_scaler.fit_transform(my_data_forPCA)\n",
    "scaled_landDiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 75)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pca_cartoon = PCA(n_components=75)#era 14\n",
    "b_cartoon = pca_cartoon.fit_transform(scaled_landDiff)\n",
    "b_cartoon.shape # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 75)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_cartoon_data = imcartoonarray[1].reshape(1,-1)\n",
    "std_scaler_instance =  StandardScaler()\n",
    "scaled_inst = std_scaler_instance.fit_transform(test_cartoon_data)\n",
    "\n",
    "\n",
    "b_cartoon_instance = pca_cartoon.transform(scaled_inst)\n",
    "b_cartoon_instance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Texture PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'im_newT_texturearray_.csv'\n",
    "chunk_size = 100\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size, header = None):\n",
    "    df_list.append(chunk)\n",
    "\n",
    "df2 = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_forPCA2 =df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_scaler = StandardScaler()\n",
    "scaled_landDiff = std_scaler.fit_transform(my_data_forPCA2)\n",
    "scaled_landDiff.shape\n",
    "\n",
    "\n",
    "pca_texture = PCA(n_components=350)#era 14\n",
    "b_texture = pca_texture.fit_transform(scaled_landDiff)\n",
    "b_texture.shape # "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solverenv",
   "language": "python",
   "name": "solverenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
