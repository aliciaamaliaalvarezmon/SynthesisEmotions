{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # NUMPY\n",
    "import pandas as pd # PANDAS\n",
    "import matplotlib.pyplot as plt # MATPLOTLIB\n",
    "import seaborn as sns # SEABORN\n",
    "import scipy\n",
    "import sklearn\n",
    "import random as rd\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "import os \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Aca vamos a sacar los b de textura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects_images = '../ck+copy/extended-cohn-kanade-images/cohn-kanade-images'\n",
    "sorted_subjects =   np.sort(os.listdir('../ck+copy/extended-cohn-kanade-images/cohn-kanade-images/')) # we probably need to not have the sorted\n",
    "\n",
    "images = []\n",
    "\n",
    "for subject in sorted_subjects:\n",
    "    one_subject_images = '../ck+copy/extended-cohn-kanade-images/cohn-kanade-images/' + str(subject)+ '/'\n",
    "    sorted_list = np.sort(os.listdir(one_subject_images)) #creo que este sort se puede quitar\n",
    "    images_per_subject = []\n",
    "    for emotion in sorted_list:\n",
    "        images__per_seqframe = []\n",
    "        subject_image_emotion = one_subject_images + str(emotion)\n",
    "        for i in range(0, len(os.listdir(subject_image_emotion))):\n",
    "            image = '../ck+copy/extended-cohn-kanade-images/cohn-kanade-images/' +  str(subject)+ '/' + str(emotion)+'/'+ str(subject)+ '_'+str(emotion)+'_'+ str(i+1).zfill(8)+'.png'\n",
    "            images__per_seqframe.append(image)        \n",
    "        images_per_subject.append(images__per_seqframe)\n",
    "    images.append(images_per_subject)   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(images)):\n",
    "    for j in range(0, len(images[i])):\n",
    "                images[i][j]= np.asarray( images[i][j], dtype=object)\n",
    "    images[i]= np.asarray( images[i], dtype=object)\n",
    "images= np.asarray( images, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 640)\n"
     ]
    }
   ],
   "source": [
    "#See if loading image works\n",
    "img= cv2.imread(images[0][0][0])\n",
    "\n",
    "img =cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_width, img_height = img.shape\n",
    "print(img.shape)\n",
    "\n",
    "cv2.imshow(\"Face landmark result\", img)\n",
    "\n",
    "# Pause screen to wait key from user to see result\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#por ahora usamos numeros enteros\n",
    "left_eye_warp = np.array([ 0.3 * img_width, float(round(img_height / 3 ))]) \n",
    "right_eye_warp =np.array([ 0.7 * img_width , float(round(img_height / 3 ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equilateral triangle\n",
    "def equilateral_point(left, right):\n",
    "    X, Y = left, right\n",
    "    M = (X + Y) / 2\n",
    "    O = (X - M) * 3**0.5\n",
    "    t = np.array([[0, -1], [1, 0]])   # 90 degree transformation matrix\n",
    "\n",
    "    thrid_point = M + O @ t\n",
    "    return thrid_point\n",
    "#\n",
    "#In []:\n",
    "#M + O @ t\n",
    "\n",
    "#Out[]:\n",
    "#array([1.5      , 1.8660254])\n",
    "\n",
    "#In []:\n",
    "#M + O @ t.T                       # the transpose gives -90\n",
    "\n",
    "#Out[]:\n",
    "#array([1.5      , 0.1339746])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([245.        , 382.74097914])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_point = equilateral_point(left_eye_warp, right_eye_warp)\n",
    "third_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343.0, 213.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_eye_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_37(point 36) y landmark 46(45) son los corners de los ojos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_landmarks = pd.read_csv('ckmock_landmark_intercalated_data.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "even = np.asarray(my_landmarks.iloc[0][::2] )\n",
    "odds = np.asarray( my_landmarks.iloc[0][1::2] )\n",
    "\n",
    "\n",
    "\n",
    "left_eye_corner = np.array([even[36], odds[36]])\n",
    "right_eye_corner = np.array([even[45], odds[45]])\n",
    "\n",
    "\n",
    "third_point_corner = equilateral_point(left_eye_corner, right_eye_corner)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 490\n",
    "cols = 640\n",
    "input_pts =  np.float32([left_eye_corner, right_eye_corner, third_point_corner])\n",
    "output_pts =  np.float32([left_eye_warp, right_eye_warp, third_point])\n",
    "M = cv2.getAffineTransform(input_pts , output_pts)\n",
    " \n",
    "# Apply the affine transformation using cv2.warpAffine()\n",
    "dst = cv2.warpAffine(img, M, (cols,rows))\n",
    " \n",
    "# Display the image\n",
    "out = cv2.hconcat([img, dst])\n",
    "cv2.imshow('Output', out)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lan =[]\n",
    "for (a, b) in zip(even, odds):\n",
    "    lan.append([[a,b]])\n",
    "    \n",
    "#np.array([ [[x1, y1]], ..., [[xn, yn]] ])\n",
    "#dst=(np.dot(M[:,:2], a.T)+M[:,2].reshape(2,1)).T\n",
    "lan =np.asarray(lan)\n",
    "transformed_landmarks = cv2.transform(lan, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets draw the landmarks in the image before and after the warp\n",
    "for landmark in lan:\n",
    " \n",
    "\n",
    "\n",
    "cv2.imshow('Output', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for landmark in lan:\n",
    "  po\n",
    "\n",
    "\n",
    "cv2.imshow('Output', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we warp all the training face images to a\n",
    "reference shape using cubic polynomial function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For that, we first load the landmarks of the procustres analysis\n",
    "used before as the references points for the warp \n",
    "(we use the intercalated ones as for now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_to_shape(image, labels, target, extend=1.0, rotate=False):\n",
    "  image = np.array(image)\n",
    "  labels = np.array(labels).astype(np.float32)\n",
    "  target = np.array(target).astype(np.float32)\n",
    "  m, _ = cv2.estimateAffinePartial2D(labels, target)\n",
    "  image_t = cv2.warpAffine(image, m, (128, 128))\n",
    "  labels_t = np.dot(labels, m[:,:2].T) + m[np.newaxis,:,2]\n",
    "  return image_t, labels_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_aligned_landmarks = pd.read_csv('ckmock_landmark_aligned_intercalated_data.csv',header = None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "my_aligned_landmarks.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.163450\n",
       "1     -0.068005\n",
       "2     -0.156895\n",
       "3     -0.028732\n",
       "4     -0.145752\n",
       "         ...   \n",
       "131    0.071911\n",
       "132    0.002726\n",
       "133    0.072451\n",
       "134   -0.014327\n",
       "135    0.071782\n",
       "Name: 0, Length: 136, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_aligned_landmarks.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ahora vamos a hacer el wrap de todas las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Por ahora estoy usando la misma imagen que en procustres. Deberia usar generalizado para hallar la de menor diferencia y usar esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
