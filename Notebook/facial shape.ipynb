{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # NUMPY\n",
    "import pandas as pd # PANDAS\n",
    "import matplotlib.pyplot as plt # MATPLOTLIB\n",
    "import seaborn as sns # SEABORN\n",
    "import scipy\n",
    "import sklearn\n",
    "import random as rd\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display\n",
    "import os \n",
    "from pathlib import Path\n",
    "import shutil \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En este notebook conseguimos el shape feature (b_shape) de nuestras imagenes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions :\n",
    "\n",
    "Cada secuencia muestra 1 de las 6 emociones b√°sicas\n",
    "\n",
    "La primer frame de cada secuencia muestra  la cara en una expression neutral\n",
    "\n",
    "La intensidad de la expresion aumenta en cada frame de un sujeto (siendo intesidad 1 el ultimo frame. Otros no asumen la mayor intensidad en ultimo frame, nosotros si)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca para imagen nueva vamos a tener que usar aam para conseguir los landmarks. Por ahora vamos a extraer el feature \n",
    "b_shape para nuestra c_mock que usaremos de entrenamiento (mock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to understansd the landmarks (annotaste) and the aam for the test image (input images)\n",
    "#TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the landmarks from the images of the ck+ database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_landmarks = '../ck+copy/Landmarks/'\n",
    "sorted_subjects =   np.sort(os.listdir('../ck+copy/Landmarks/')) # we probably need to not have the sorted\n",
    "\n",
    "distances = []\n",
    "for subject in sorted_subjects:\n",
    "    one_subject_landmarks = '../ck+copy/Landmarks/' + str(subject)+ '/'\n",
    "    sorted_list = np.sort(os.listdir(one_subject_landmarks)) \n",
    "    distances_per_subject = []\n",
    "    for emotion in sorted_list:\n",
    "        matrix_landmark_per_frame = []\n",
    "        subject_landmark_emotion = one_subject_landmarks + str(emotion)    \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_landmarks = '../ck+copy/Landmarks/'\n",
    "sorted_subjects =   np.sort(os.listdir('../ck+copy/Landmarks/')) # we probably need to not have the sorted\n",
    "\n",
    "distances = []\n",
    "for subject in sorted_subjects:\n",
    "    one_subject_landmarks = '../ck+copy/Landmarks/' + str(subject)+ '/'\n",
    "    sorted_list = np.sort(os.listdir(one_subject_landmarks)) #creo que este sort se puede quitar\n",
    "    distances_per_subject = []\n",
    "    for emotion in sorted_list:\n",
    "        matrix_landmark_per_frame = []\n",
    "        subject_landmark_emotion = one_subject_landmarks + str(emotion)    \n",
    "        for i in range(0, len(os.listdir(subject_landmark_emotion))):\n",
    "            data = pd.read_csv('../ck+copy/Landmarks/' +  str(subject)+ '/' + str(emotion)+'/'+ str(subject)+ '_'+str(emotion)+'_'+ str(i+1).zfill(8)+'_landmarks.txt',  header=None)\n",
    "            data.columns =['landmarks']\n",
    "            quantity_of_landmarks = data.size #68\n",
    "            data = data['landmarks'].str.split('   ', expand=True)\n",
    "            data.columns =['landmarks', 'landmarkX', 'landmarkY']\n",
    "            data =data.drop(columns=['landmarks'])\n",
    "            landmarkXY=data['landmarkX'].append(data['landmarkY'], ignore_index=True)\n",
    "            landmarkXY_array =landmarkXY.to_numpy(dtype=float)\n",
    "            matrix_landmark_per_frame.append(landmarkXY_array)\n",
    "        frame0 = matrix_landmark_per_frame[0]\n",
    "        distance_landmark_per_frame = matrix_landmark_per_frame\n",
    "        for i in range(0, len(distance_landmark_per_frame)):\n",
    "            distance_landmark_per_frame[i] = distance_landmark_per_frame[i] - frame0\n",
    "        distances_per_subject.append(distance_landmark_per_frame)\n",
    "    distances.append(distances_per_subject)\n",
    "#tenemos matrix que por cada sujeto tiene una matriz con cada emocion, que por cada distancia por emocion tiene vector con la distancia de frames con el primero por emocion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for subject in sorted_subjects:\n",
    "    one_subject_landmarks = '../ck+copy/Landmarks/' + str(subject)+ '/'\n",
    "    sorted_list = np.sort(os.listdir(one_subject_landmarks)) #creo que este sort se puede quitar\n",
    "    distances_per_subject = []\n",
    "    for emotion in sorted_list:\n",
    "        matrix_landmark_per_frame = []\n",
    "        subject_landmark_emotion = one_subject_landmarks + str(emotion)    \n",
    "        for i in range(0, len(os.listdir(subject_landmark_emotion))):\n",
    "            data = pd.read_csv('../ck+copy/Landmarks/' +  str(subject)+ '/' + str(emotion)+'/'+ str(subject)+ '_'+str(emotion)+'_'+ str(i+1).zfill(8)+'_landmarks.txt',  header=None)\n",
    "            data.columns =['landmarks']\n",
    "            quantity_of_landmarks = data.size #68\n",
    "            data = data['landmarks'].str.split('   ', expand=True)\n",
    "            data.columns =['landmarks', 'landmarkX', 'landmarkY']\n",
    "            data =data.drop(columns=['landmarks'])\n",
    "            landmarkXY=data['landmarkX'].append(data['landmarkY'], ignore_index=True)\n",
    "            landmarkXY_array =landmarkXY.to_numpy(dtype=float)\n",
    "            matrix_landmark_per_frame.append(landmarkXY_array)        \n",
    "        distance_landmark_per_frame = matrix_landmark_per_frame       \n",
    "        distances_per_subject.append(distance_landmark_per_frame)\n",
    "    distances.append(distances_per_subject)\n",
    "#tenemos matrix que por cada sujeto tiene una matriz con cada emocion, que por cada distancia por emocion tiene vector con la distancia de frames con el primero por emocion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aca convertimos  en array y agrupamos por secuencia de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 136)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(distances)):\n",
    "    for j in range(0, len( distances[i])):\n",
    "        distances[i][j]= np.asarray( distances[i][j], dtype=object)\n",
    "    distances[i]= np.asarray( distances[i], dtype=object)\n",
    "distances= np.asarray( distances, dtype=object)\n",
    "print(distances[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aca  convertimos en array y apilamos todos los frames de todas las secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(965, 136)\n"
     ]
    }
   ],
   "source": [
    "stacked_array = []\n",
    "for i in range(0, len(distances)):\n",
    "    stacked_array.append(np.vstack(tuple(distances[i])))\n",
    "stacked_array= np.asarray( stacked_array, dtype=object)\n",
    "total_stacked_landmarkRawData = np.vstack(tuple(stacked_array))\n",
    "print(total_stacked_landmarkRawData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(total_stacked_landmarkRawData)\n",
    "my_df.to_csv('ckmock_landmark_rawData.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aca  separamos las primeras frames de cada secuencia, ( cara  neutral), y la cantidad de frames por secuencia, para poder luego sacar las diferencia entre los landmarks de los frames de una secuencia  y el primer frame de esta (cara neutral). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame =[]\n",
    "cant_frame_per_seq = []\n",
    "for i in range(0, len(distances)):\n",
    "    for j in range(0, len( distances[i])):\n",
    "        first_frame.append(distances[i][j][0])\n",
    "        cant_frame_per_seq.append(len(distances[i][j]))\n",
    "        \n",
    "\n",
    "first_frame = np.asarray( first_frame, dtype=object)\n",
    "cant_frame_per_seq = np.asarray( cant_frame_per_seq, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51, 136),\n",
       " array([29, 16, 30, 19, 17, 30, 17, 33, 23, 32, 17, 19, 12, 29, 25, 14, 24,\n",
       "        15, 14, 10, 21, 13, 29, 28, 14, 21, 14, 33, 17, 19, 27, 22, 20, 13,\n",
       "        14, 15, 13, 5, 23, 16, 14, 15, 7, 6, 27, 20, 10, 22, 9, 15, 18],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_frame.shape, cant_frame_per_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(first_frame)\n",
    "my_df.to_csv('ckmock_landmark_firstFrame.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(cant_frame_per_seq)\n",
    "my_df.to_csv('ckmock_landmark_FramePerSeq.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alineaci√≥n de shapes con procustres.\n",
    "\n",
    "## Ahora, para que todas nuestras imagenes est√©n alineadas, utilizamos Procustres analysis. \n",
    "\n",
    "Este analisis, en su version normal, utiliza una imagen de referencia y luego encuentra las transformaciones de rotacion,  translacion y escala que minimizen la diferencia con esa imagen \n",
    "\n",
    "(La versi√≥n generalizada en cambio ve las distancias de la aproximacion de entre todos los pares y elije la imagen cuyas distancias son menores ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EL procustres de spicy devuelve los landmarks corridos, pero no devuelve \n",
    "las matrices de trasnformaci√≥n, que son necesarias para luego hacer warp de las imagenes\n",
    "en tiempo polinomial.\n",
    "\n",
    "Ac√° primero lo hacemos con spicy (normal) y luego con un computo de procustres.\n",
    "(normal y generalizado)\n",
    "\n",
    "Vemos las diferencias y como dan los b_shapes con cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we have todo procustres and we need noormalization of the landmark differences, (la normalizacion es la resta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245.68800</td>\n",
       "      <td>250.75381</td>\n",
       "      <td>259.36702</td>\n",
       "      <td>266.68465</td>\n",
       "      <td>277.26378</td>\n",
       "      <td>295.88027</td>\n",
       "      <td>319.49635</td>\n",
       "      <td>346.07042</td>\n",
       "      <td>375.99423</td>\n",
       "      <td>406.69956</td>\n",
       "      <td>...</td>\n",
       "      <td>372.84879</td>\n",
       "      <td>368.30900</td>\n",
       "      <td>358.95264</td>\n",
       "      <td>357.22541</td>\n",
       "      <td>356.73931</td>\n",
       "      <td>357.43714</td>\n",
       "      <td>359.24213</td>\n",
       "      <td>360.59360</td>\n",
       "      <td>361.01155</td>\n",
       "      <td>360.49401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>245.68800</td>\n",
       "      <td>250.75381</td>\n",
       "      <td>259.36702</td>\n",
       "      <td>266.68465</td>\n",
       "      <td>277.26378</td>\n",
       "      <td>295.88027</td>\n",
       "      <td>319.49635</td>\n",
       "      <td>346.07042</td>\n",
       "      <td>375.99423</td>\n",
       "      <td>406.69956</td>\n",
       "      <td>...</td>\n",
       "      <td>372.84879</td>\n",
       "      <td>368.30900</td>\n",
       "      <td>358.95264</td>\n",
       "      <td>357.22541</td>\n",
       "      <td>356.73931</td>\n",
       "      <td>357.43714</td>\n",
       "      <td>359.24213</td>\n",
       "      <td>360.59360</td>\n",
       "      <td>361.01155</td>\n",
       "      <td>360.49401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245.68800</td>\n",
       "      <td>250.75381</td>\n",
       "      <td>259.36702</td>\n",
       "      <td>266.68465</td>\n",
       "      <td>277.26378</td>\n",
       "      <td>295.88027</td>\n",
       "      <td>319.49635</td>\n",
       "      <td>346.07042</td>\n",
       "      <td>375.99423</td>\n",
       "      <td>406.69956</td>\n",
       "      <td>...</td>\n",
       "      <td>372.84879</td>\n",
       "      <td>368.30900</td>\n",
       "      <td>358.95264</td>\n",
       "      <td>357.22541</td>\n",
       "      <td>356.73931</td>\n",
       "      <td>357.43714</td>\n",
       "      <td>359.24213</td>\n",
       "      <td>360.59360</td>\n",
       "      <td>361.01155</td>\n",
       "      <td>360.49401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>245.52430</td>\n",
       "      <td>250.60603</td>\n",
       "      <td>259.24738</td>\n",
       "      <td>266.58873</td>\n",
       "      <td>277.18849</td>\n",
       "      <td>295.83317</td>\n",
       "      <td>319.48002</td>\n",
       "      <td>346.10317</td>\n",
       "      <td>376.06987</td>\n",
       "      <td>406.81441</td>\n",
       "      <td>...</td>\n",
       "      <td>372.94551</td>\n",
       "      <td>368.40449</td>\n",
       "      <td>359.04407</td>\n",
       "      <td>357.29451</td>\n",
       "      <td>356.80126</td>\n",
       "      <td>357.49982</td>\n",
       "      <td>359.32130</td>\n",
       "      <td>360.69453</td>\n",
       "      <td>361.13300</td>\n",
       "      <td>360.60285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245.63147</td>\n",
       "      <td>250.71666</td>\n",
       "      <td>259.34747</td>\n",
       "      <td>266.69404</td>\n",
       "      <td>277.31085</td>\n",
       "      <td>295.95780</td>\n",
       "      <td>319.60644</td>\n",
       "      <td>346.21376</td>\n",
       "      <td>376.18077</td>\n",
       "      <td>406.91947</td>\n",
       "      <td>...</td>\n",
       "      <td>372.97670</td>\n",
       "      <td>368.39557</td>\n",
       "      <td>358.98119</td>\n",
       "      <td>357.21598</td>\n",
       "      <td>356.71773</td>\n",
       "      <td>357.41864</td>\n",
       "      <td>359.25529</td>\n",
       "      <td>360.66201</td>\n",
       "      <td>361.11404</td>\n",
       "      <td>360.56986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>193.60994</td>\n",
       "      <td>191.96195</td>\n",
       "      <td>191.42480</td>\n",
       "      <td>194.13260</td>\n",
       "      <td>207.74205</td>\n",
       "      <td>230.90409</td>\n",
       "      <td>258.54349</td>\n",
       "      <td>287.82045</td>\n",
       "      <td>321.88795</td>\n",
       "      <td>358.46063</td>\n",
       "      <td>...</td>\n",
       "      <td>373.03568</td>\n",
       "      <td>366.71602</td>\n",
       "      <td>349.56848</td>\n",
       "      <td>349.36120</td>\n",
       "      <td>351.31250</td>\n",
       "      <td>349.56220</td>\n",
       "      <td>349.68906</td>\n",
       "      <td>349.81593</td>\n",
       "      <td>352.25400</td>\n",
       "      <td>349.77576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>193.57935</td>\n",
       "      <td>191.91649</td>\n",
       "      <td>191.40544</td>\n",
       "      <td>194.11941</td>\n",
       "      <td>207.71431</td>\n",
       "      <td>230.91723</td>\n",
       "      <td>258.56952</td>\n",
       "      <td>287.86400</td>\n",
       "      <td>321.94880</td>\n",
       "      <td>358.54341</td>\n",
       "      <td>...</td>\n",
       "      <td>373.32072</td>\n",
       "      <td>367.02409</td>\n",
       "      <td>349.84369</td>\n",
       "      <td>349.65369</td>\n",
       "      <td>351.55793</td>\n",
       "      <td>349.88613</td>\n",
       "      <td>349.97891</td>\n",
       "      <td>350.07169</td>\n",
       "      <td>352.45317</td>\n",
       "      <td>350.03369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>193.41618</td>\n",
       "      <td>191.77914</td>\n",
       "      <td>191.30121</td>\n",
       "      <td>194.05367</td>\n",
       "      <td>207.68432</td>\n",
       "      <td>230.93460</td>\n",
       "      <td>258.64083</td>\n",
       "      <td>287.95782</td>\n",
       "      <td>322.07101</td>\n",
       "      <td>358.69361</td>\n",
       "      <td>...</td>\n",
       "      <td>373.46142</td>\n",
       "      <td>367.19207</td>\n",
       "      <td>350.00780</td>\n",
       "      <td>349.83455</td>\n",
       "      <td>351.72253</td>\n",
       "      <td>350.01896</td>\n",
       "      <td>350.08910</td>\n",
       "      <td>350.15924</td>\n",
       "      <td>352.56142</td>\n",
       "      <td>350.18105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>193.45437</td>\n",
       "      <td>191.84596</td>\n",
       "      <td>191.33606</td>\n",
       "      <td>194.08412</td>\n",
       "      <td>207.74749</td>\n",
       "      <td>230.95040</td>\n",
       "      <td>258.64575</td>\n",
       "      <td>287.96100</td>\n",
       "      <td>322.06519</td>\n",
       "      <td>358.66876</td>\n",
       "      <td>...</td>\n",
       "      <td>373.36790</td>\n",
       "      <td>367.05972</td>\n",
       "      <td>349.90446</td>\n",
       "      <td>349.69817</td>\n",
       "      <td>351.64340</td>\n",
       "      <td>349.82305</td>\n",
       "      <td>349.95286</td>\n",
       "      <td>350.08266</td>\n",
       "      <td>352.57673</td>\n",
       "      <td>350.11074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>193.31863</td>\n",
       "      <td>191.76772</td>\n",
       "      <td>191.26226</td>\n",
       "      <td>194.03972</td>\n",
       "      <td>207.76731</td>\n",
       "      <td>230.96261</td>\n",
       "      <td>258.67931</td>\n",
       "      <td>288.02376</td>\n",
       "      <td>322.13986</td>\n",
       "      <td>358.73891</td>\n",
       "      <td>...</td>\n",
       "      <td>373.38361</td>\n",
       "      <td>367.05635</td>\n",
       "      <td>349.90948</td>\n",
       "      <td>349.67327</td>\n",
       "      <td>351.64110</td>\n",
       "      <td>349.68633</td>\n",
       "      <td>349.86972</td>\n",
       "      <td>350.05310</td>\n",
       "      <td>352.66032</td>\n",
       "      <td>350.14570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows √ó 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "0    245.68800  250.75381  259.36702  266.68465  277.26378  295.88027   \n",
       "1    245.68800  250.75381  259.36702  266.68465  277.26378  295.88027   \n",
       "2    245.68800  250.75381  259.36702  266.68465  277.26378  295.88027   \n",
       "3    245.52430  250.60603  259.24738  266.58873  277.18849  295.83317   \n",
       "4    245.63147  250.71666  259.34747  266.69404  277.31085  295.95780   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "960  193.60994  191.96195  191.42480  194.13260  207.74205  230.90409   \n",
       "961  193.57935  191.91649  191.40544  194.11941  207.71431  230.91723   \n",
       "962  193.41618  191.77914  191.30121  194.05367  207.68432  230.93460   \n",
       "963  193.45437  191.84596  191.33606  194.08412  207.74749  230.95040   \n",
       "964  193.31863  191.76772  191.26226  194.03972  207.76731  230.96261   \n",
       "\n",
       "           6          7          8          9    ...        126        127  \\\n",
       "0    319.49635  346.07042  375.99423  406.69956  ...  372.84879  368.30900   \n",
       "1    319.49635  346.07042  375.99423  406.69956  ...  372.84879  368.30900   \n",
       "2    319.49635  346.07042  375.99423  406.69956  ...  372.84879  368.30900   \n",
       "3    319.48002  346.10317  376.06987  406.81441  ...  372.94551  368.40449   \n",
       "4    319.60644  346.21376  376.18077  406.91947  ...  372.97670  368.39557   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "960  258.54349  287.82045  321.88795  358.46063  ...  373.03568  366.71602   \n",
       "961  258.56952  287.86400  321.94880  358.54341  ...  373.32072  367.02409   \n",
       "962  258.64083  287.95782  322.07101  358.69361  ...  373.46142  367.19207   \n",
       "963  258.64575  287.96100  322.06519  358.66876  ...  373.36790  367.05972   \n",
       "964  258.67931  288.02376  322.13986  358.73891  ...  373.38361  367.05635   \n",
       "\n",
       "           128        129        130        131        132        133  \\\n",
       "0    358.95264  357.22541  356.73931  357.43714  359.24213  360.59360   \n",
       "1    358.95264  357.22541  356.73931  357.43714  359.24213  360.59360   \n",
       "2    358.95264  357.22541  356.73931  357.43714  359.24213  360.59360   \n",
       "3    359.04407  357.29451  356.80126  357.49982  359.32130  360.69453   \n",
       "4    358.98119  357.21598  356.71773  357.41864  359.25529  360.66201   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "960  349.56848  349.36120  351.31250  349.56220  349.68906  349.81593   \n",
       "961  349.84369  349.65369  351.55793  349.88613  349.97891  350.07169   \n",
       "962  350.00780  349.83455  351.72253  350.01896  350.08910  350.15924   \n",
       "963  349.90446  349.69817  351.64340  349.82305  349.95286  350.08266   \n",
       "964  349.90948  349.67327  351.64110  349.68633  349.86972  350.05310   \n",
       "\n",
       "           134        135  \n",
       "0    361.01155  360.49401  \n",
       "1    361.01155  360.49401  \n",
       "2    361.01155  360.49401  \n",
       "3    361.13300  360.60285  \n",
       "4    361.11404  360.56986  \n",
       "..         ...        ...  \n",
       "960  352.25400  349.77576  \n",
       "961  352.45317  350.03369  \n",
       "962  352.56142  350.18105  \n",
       "963  352.57673  350.11074  \n",
       "964  352.66032  350.14570  \n",
       "\n",
       "[965 rows x 136 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = pd.read_csv('ckmock_landmark_rawData.csv',header = None)\n",
    "my_data #estas son las shapes sin la diferencia [x1...xl,y1..yl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En estas 2 celdas cambiamos el formato, para tener los datos en forma intercalada (x1,y1,x2,y2) y xy (x1,x2..xn,y1,y2..yn). Usamos este √∫ltimo para b_shape como dice el paper, pero para procuestres lo usamos en orden intercalado (de a pares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 136)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cambiamos a [x1, y1, x2,y2]\n",
    "intercalated_data =[]\n",
    "for i in range(0,len(my_data)):\n",
    "    x_coord =my_data.iloc[i][0:int(len(my_data.iloc[i])/2)]\n",
    "    y_coord = my_data.iloc[i][int(len(my_data.iloc[i])/2):len(my_data.iloc[i])]\n",
    "    output = []\n",
    "    for (a, b) in zip(x_coord, y_coord):\n",
    "        output.append(a)\n",
    "        output.append(b)\n",
    "    intercalated_data.append(np.asarray(output))\n",
    "intercalated_data = np.asarray(intercalated_data)\n",
    "intercalated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(intercalated_data)\n",
    "my_df.to_csv('ckmock_landmark_intercalated_data.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 68, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ahora lo hacemos en pares\n",
    "#Cambiamos a [x1, y1, x2,y2]\n",
    "intercalated_data =[]\n",
    "for i in range(0,len(my_data)):\n",
    "    x_coord =my_data.iloc[i][0:int(len(my_data.iloc[i])/2)]\n",
    "    y_coord = my_data.iloc[i][int(len(my_data.iloc[i])/2):len(my_data.iloc[i])]\n",
    "    output = []\n",
    "    for (a, b) in zip(x_coord, y_coord):\n",
    "        output.append(np.array([a,b]))        \n",
    "    intercalated_data.append(np.asarray(output))\n",
    "intercalated_data = np.asarray(intercalated_data)\n",
    "intercalated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Procustres\n",
    "#Usamos la primera imagen como shape de referencia (puede generalizarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from scipy.spatial import procrustes\n",
    "\n",
    "aligned_data = []\n",
    "for i in range(1, len(intercalated_data)):\n",
    "    mtx1, mtx2, disparity = procrustes(intercalated_data[0], intercalated_data[i])\n",
    "    if(i == 1):\n",
    "        aligned_data.append(mtx1)\n",
    "        aligned_data.append(mtx2)\n",
    "    else:\n",
    "        aligned_data.append(mtx2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_data[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 136)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_data_intercalated = []\n",
    "for i in range(0, len(aligned_data)):\n",
    "    aligned_data_intercalated.append(aligned_data[i].flatten())\n",
    "#np.asarray(aligned_data_intercalated).shape\n",
    "aligned_data_intercalated = np.asarray(aligned_data_intercalated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(aligned_data_intercalated)\n",
    "my_df.to_csv('ckmock_landmark_aligned_intercalated_data.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06800458899401303"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_data_xy = []\n",
    "for i in range(0, len(aligned_data)):\n",
    "    aligned_data_xy.append(aligned_data[i].flatten('F'))\n",
    "#np.asarray(aligned_data_intercalated).shape\n",
    "aligned_data_xy = np.asarray(aligned_data_xy)\n",
    "aligned_data_xy[0][68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(aligned_data_xy)\n",
    "my_df.to_csv('ckmock_landmark_aligned_xy.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora si, trabajamos con esta data alineada en orden xy. Luego de cargala, conseguimos la diferencia con cada frame 0 por secuencia, y con esos datos utilizamos PCA para  encontrar los b_shape, que tienen dimension #principal_component x 1 para cada frame . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.163450</td>\n",
       "      <td>-0.156895</td>\n",
       "      <td>-0.145752</td>\n",
       "      <td>-0.136284</td>\n",
       "      <td>-0.122597</td>\n",
       "      <td>-0.098510</td>\n",
       "      <td>-0.067956</td>\n",
       "      <td>-0.033574</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.044869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087766</td>\n",
       "      <td>0.081893</td>\n",
       "      <td>0.069788</td>\n",
       "      <td>0.067553</td>\n",
       "      <td>0.066924</td>\n",
       "      <td>0.067827</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>0.071911</td>\n",
       "      <td>0.072451</td>\n",
       "      <td>0.071782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.163450</td>\n",
       "      <td>-0.156895</td>\n",
       "      <td>-0.145752</td>\n",
       "      <td>-0.136284</td>\n",
       "      <td>-0.122597</td>\n",
       "      <td>-0.098510</td>\n",
       "      <td>-0.067956</td>\n",
       "      <td>-0.033574</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.044869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087766</td>\n",
       "      <td>0.081893</td>\n",
       "      <td>0.069788</td>\n",
       "      <td>0.067553</td>\n",
       "      <td>0.066924</td>\n",
       "      <td>0.067827</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>0.071911</td>\n",
       "      <td>0.072451</td>\n",
       "      <td>0.071782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.163450</td>\n",
       "      <td>-0.156895</td>\n",
       "      <td>-0.145752</td>\n",
       "      <td>-0.136284</td>\n",
       "      <td>-0.122597</td>\n",
       "      <td>-0.098510</td>\n",
       "      <td>-0.067956</td>\n",
       "      <td>-0.033574</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.044869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087766</td>\n",
       "      <td>0.081893</td>\n",
       "      <td>0.069788</td>\n",
       "      <td>0.067553</td>\n",
       "      <td>0.066924</td>\n",
       "      <td>0.067827</td>\n",
       "      <td>0.070162</td>\n",
       "      <td>0.071911</td>\n",
       "      <td>0.072451</td>\n",
       "      <td>0.071782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.163462</td>\n",
       "      <td>-0.156908</td>\n",
       "      <td>-0.145755</td>\n",
       "      <td>-0.136281</td>\n",
       "      <td>-0.122597</td>\n",
       "      <td>-0.098517</td>\n",
       "      <td>-0.067972</td>\n",
       "      <td>-0.033580</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.044863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087772</td>\n",
       "      <td>0.081898</td>\n",
       "      <td>0.069807</td>\n",
       "      <td>0.067551</td>\n",
       "      <td>0.066919</td>\n",
       "      <td>0.067826</td>\n",
       "      <td>0.070184</td>\n",
       "      <td>0.071954</td>\n",
       "      <td>0.072516</td>\n",
       "      <td>0.071826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.163406</td>\n",
       "      <td>-0.156854</td>\n",
       "      <td>-0.145720</td>\n",
       "      <td>-0.136245</td>\n",
       "      <td>-0.122544</td>\n",
       "      <td>-0.098467</td>\n",
       "      <td>-0.067924</td>\n",
       "      <td>-0.033558</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.044874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087870</td>\n",
       "      <td>0.081942</td>\n",
       "      <td>0.069783</td>\n",
       "      <td>0.067510</td>\n",
       "      <td>0.066874</td>\n",
       "      <td>0.067786</td>\n",
       "      <td>0.070165</td>\n",
       "      <td>0.071976</td>\n",
       "      <td>0.072554</td>\n",
       "      <td>0.071843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-0.148756</td>\n",
       "      <td>-0.148653</td>\n",
       "      <td>-0.147350</td>\n",
       "      <td>-0.142510</td>\n",
       "      <td>-0.125884</td>\n",
       "      <td>-0.099116</td>\n",
       "      <td>-0.067693</td>\n",
       "      <td>-0.034620</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.042856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087104</td>\n",
       "      <td>0.081242</td>\n",
       "      <td>0.062722</td>\n",
       "      <td>0.061722</td>\n",
       "      <td>0.062258</td>\n",
       "      <td>0.058505</td>\n",
       "      <td>0.057794</td>\n",
       "      <td>0.058807</td>\n",
       "      <td>0.063288</td>\n",
       "      <td>0.062188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>-0.148671</td>\n",
       "      <td>-0.147348</td>\n",
       "      <td>-0.142510</td>\n",
       "      <td>-0.125914</td>\n",
       "      <td>-0.099120</td>\n",
       "      <td>-0.067702</td>\n",
       "      <td>-0.034628</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.042855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087195</td>\n",
       "      <td>0.081358</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>0.061829</td>\n",
       "      <td>0.062320</td>\n",
       "      <td>0.058664</td>\n",
       "      <td>0.057920</td>\n",
       "      <td>0.058891</td>\n",
       "      <td>0.063298</td>\n",
       "      <td>0.062257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>-0.148761</td>\n",
       "      <td>-0.148685</td>\n",
       "      <td>-0.147358</td>\n",
       "      <td>-0.142514</td>\n",
       "      <td>-0.125920</td>\n",
       "      <td>-0.099120</td>\n",
       "      <td>-0.067688</td>\n",
       "      <td>-0.034631</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.042849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087149</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.062785</td>\n",
       "      <td>0.061839</td>\n",
       "      <td>0.062338</td>\n",
       "      <td>0.058680</td>\n",
       "      <td>0.057926</td>\n",
       "      <td>0.058856</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.062230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>-0.148763</td>\n",
       "      <td>-0.148652</td>\n",
       "      <td>-0.147356</td>\n",
       "      <td>-0.142512</td>\n",
       "      <td>-0.125875</td>\n",
       "      <td>-0.099113</td>\n",
       "      <td>-0.067682</td>\n",
       "      <td>-0.034619</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087044</td>\n",
       "      <td>0.081181</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.061684</td>\n",
       "      <td>0.062242</td>\n",
       "      <td>0.058448</td>\n",
       "      <td>0.057757</td>\n",
       "      <td>0.058756</td>\n",
       "      <td>0.063262</td>\n",
       "      <td>0.062147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>-0.148765</td>\n",
       "      <td>-0.148622</td>\n",
       "      <td>-0.147354</td>\n",
       "      <td>-0.142509</td>\n",
       "      <td>-0.125834</td>\n",
       "      <td>-0.099108</td>\n",
       "      <td>-0.067679</td>\n",
       "      <td>-0.034608</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086955</td>\n",
       "      <td>0.081053</td>\n",
       "      <td>0.062549</td>\n",
       "      <td>0.061548</td>\n",
       "      <td>0.062157</td>\n",
       "      <td>0.058244</td>\n",
       "      <td>0.057626</td>\n",
       "      <td>0.058671</td>\n",
       "      <td>0.063272</td>\n",
       "      <td>0.062075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>965 rows √ó 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0   -0.163450 -0.156895 -0.145752 -0.136284 -0.122597 -0.098510 -0.067956   \n",
       "1   -0.163450 -0.156895 -0.145752 -0.136284 -0.122597 -0.098510 -0.067956   \n",
       "2   -0.163450 -0.156895 -0.145752 -0.136284 -0.122597 -0.098510 -0.067956   \n",
       "3   -0.163462 -0.156908 -0.145755 -0.136281 -0.122597 -0.098517 -0.067972   \n",
       "4   -0.163406 -0.156854 -0.145720 -0.136245 -0.122544 -0.098467 -0.067924   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "960 -0.148756 -0.148653 -0.147350 -0.142510 -0.125884 -0.099116 -0.067693   \n",
       "961 -0.148750 -0.148671 -0.147348 -0.142510 -0.125914 -0.099120 -0.067702   \n",
       "962 -0.148761 -0.148685 -0.147358 -0.142514 -0.125920 -0.099120 -0.067688   \n",
       "963 -0.148763 -0.148652 -0.147356 -0.142512 -0.125875 -0.099113 -0.067682   \n",
       "964 -0.148765 -0.148622 -0.147354 -0.142509 -0.125834 -0.099108 -0.067679   \n",
       "\n",
       "          7         8         9    ...       126       127       128  \\\n",
       "0   -0.033574  0.005142  0.044869  ...  0.087766  0.081893  0.069788   \n",
       "1   -0.033574  0.005142  0.044869  ...  0.087766  0.081893  0.069788   \n",
       "2   -0.033574  0.005142  0.044869  ...  0.087766  0.081893  0.069788   \n",
       "3   -0.033580  0.005137  0.044863  ...  0.087772  0.081898  0.069807   \n",
       "4   -0.033558  0.005157  0.044874  ...  0.087870  0.081942  0.069783   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "960 -0.034620  0.002989  0.042856  ...  0.087104  0.081242  0.062722   \n",
       "961 -0.034628  0.002981  0.042855  ...  0.087195  0.081358  0.062807   \n",
       "962 -0.034631  0.002974  0.042849  ...  0.087149  0.081329  0.062785   \n",
       "963 -0.034619  0.002988  0.042853  ...  0.087044  0.081181  0.062667   \n",
       "964 -0.034608  0.003001  0.042857  ...  0.086955  0.081053  0.062549   \n",
       "\n",
       "          129       130       131       132       133       134       135  \n",
       "0    0.067553  0.066924  0.067827  0.070162  0.071911  0.072451  0.071782  \n",
       "1    0.067553  0.066924  0.067827  0.070162  0.071911  0.072451  0.071782  \n",
       "2    0.067553  0.066924  0.067827  0.070162  0.071911  0.072451  0.071782  \n",
       "3    0.067551  0.066919  0.067826  0.070184  0.071954  0.072516  0.071826  \n",
       "4    0.067510  0.066874  0.067786  0.070165  0.071976  0.072554  0.071843  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "960  0.061722  0.062258  0.058505  0.057794  0.058807  0.063288  0.062188  \n",
       "961  0.061829  0.062320  0.058664  0.057920  0.058891  0.063298  0.062257  \n",
       "962  0.061839  0.062338  0.058680  0.057926  0.058856  0.063253  0.062230  \n",
       "963  0.061684  0.062242  0.058448  0.057757  0.058756  0.063262  0.062147  \n",
       "964  0.061548  0.062157  0.058244  0.057626  0.058671  0.063272  0.062075  \n",
       "\n",
       "[965 rows x 136 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = pd.read_csv('ckmock_landmark_aligned_xy.csv',header = None)\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_frames_per_seq = pd.read_csv('ckmock_landmark_FramePerSeq.csv',header = None)\n",
    "cant_frames_per_seq =np.asarray(cant_frames_per_seq).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind =0\n",
    "my_data_aligned_diff =[]\n",
    "for i in range(0, len(cant_frames_per_seq)):#51\n",
    "    cant_frames = cant_frames_per_seq[i]\n",
    "    frame_zero = my_data.iloc[ind]    \n",
    "    for j in range(ind, ind + cant_frames):\n",
    "        my_data_aligned_diff.append(my_data.iloc[j]- my_data.iloc[ind]) #no dice nada de abs\n",
    "    ind = ind + cant_frames\n",
    "    \n",
    "my_data_aligned_diff = np.asarray(my_data_aligned_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(my_data_aligned_diff)\n",
    "my_df.to_csv('my_data_aligned_diff.csv',header = False, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora hacemos PCA\n",
    "\n",
    "En el paper nos dice que restaramos el mean por columna, nosotros tambien normalizamos por standard deviation (dividimos).\n",
    "La cantidad de xomponentes es la minima que alcanze un 99% loadings, en este caso 38."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 136)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "scaled_landDiff = std_scaler.fit_transform(my_data_aligned_diff)\n",
    "scaled_landDiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(965, 38)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=38)\n",
    "pca.fit_transform(scaled_landDiff)\n",
    "b_shape = pca.fit_transform(scaled_landDiff)\n",
    "b_shape.shape # cada fila deberia ser el b de 1 frame en 38 componentes proncipales (de 136 2*l landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9907696428747979\n"
     ]
    }
   ],
   "source": [
    "print(sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " cada fila deberia ser el b de 1 frame en 38 componentes proncipales (de 136 2*l landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aca deberiamos graficar el impacto de los principal componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
